{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8lHpezSp__z",
        "outputId": "777456a1-cb25-4710-b771-416993af2c34"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkVRToWke-8-",
        "outputId": "7cbcfaa7-0a7e-4054-91a6-ac908c9a5d53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import collections\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AuIG7oPhe-9E"
      },
      "outputs": [],
      "source": [
        "text_file = \"/content/drive/MyDrive/corpus_100k.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GjlVztnZe-9E"
      },
      "outputs": [],
      "source": [
        "with open(text_file, 'r', encoding = 'utf-8') as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6wzg_VR4e-9F",
        "outputId": "2131351e-dd1a-45f5-b377-f2b2a7168535"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Հիմա ես կարող է մի բառ մի քիչ անզգույշ արտահայտեմ , եւ երեք ամիս ՀՀ ներքաղաքական կյանքն այդպես էլ չխ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "text[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IxSFdh9te-9G"
      },
      "outputs": [],
      "source": [
        "def replace_punctuation(text):\n",
        "\n",
        "  punctuation = re.compile(r\"[^\\w\\s]\")\n",
        "  text = punctuation.sub(\" \", text)\n",
        "\n",
        "  text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "  pattern = re.compile(r\"\\s+\")\n",
        "  text = pattern.sub(\" \", text)\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = replace_punctuation(text)\n",
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qugn72yjoxQZ",
        "outputId": "9ddb9f42-9548-41bf-a206-64360e73ff0d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Հիմա ես կարող է մի բառ մի քիչ անզգույշ արտահայտեմ եւ երեք ամիս ՀՀ ներքաղաքական կյանքն այդպես էլ չխաղ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZysJkoBme-9H"
      },
      "outputs": [],
      "source": [
        "def build_vocabulary(text, vocabulary_size):\n",
        "\n",
        "  text = text.lower()\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "\n",
        "  counter = collections.Counter(tokens)\n",
        "\n",
        "  top_n_words = []\n",
        "  for word, count in counter.most_common(vocabulary_size):\n",
        "    word = word.strip()\n",
        "    top_n_words.append(word)\n",
        "\n",
        "  return top_n_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pirYU0ebe-9H"
      },
      "outputs": [],
      "source": [
        "vocabulary = build_vocabulary(text, 2500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jHVSe-rRe-9H"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/vocab.txt', 'w') as f:\n",
        "    f.write(str(vocabulary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9jfXoUACe-9I"
      },
      "outputs": [],
      "source": [
        "def create_training_dataset(word_sequence, window_size):\n",
        "\n",
        "  skip_grams = []\n",
        "  for i in range(1, len(word_sequence) - 1):\n",
        "    input = word_sequence[i]\n",
        "    context = []\n",
        "    for j in range(-window_size, window_size + 1):\n",
        "      if j != 0 and 0 <= i + j < len(word_sequence):\n",
        "        context.append(word_sequence[i + j])\n",
        "\n",
        "    for w in context:\n",
        "      skip_grams.append([input, w])\n",
        "\n",
        "  return skip_grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_vSLFCHe-9I",
        "outputId": "5b9c5619-f9b6-40e5-8d69-6181a046dcaf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['որ', 'է'],\n",
              " ['որ', 'են'],\n",
              " ['որ', 'և'],\n",
              " ['են', 'է'],\n",
              " ['են', 'որ'],\n",
              " ['են', 'և'],\n",
              " ['են', 'եւ'],\n",
              " ['և', 'որ'],\n",
              " ['և', 'են'],\n",
              " ['և', 'եւ'],\n",
              " ['և', 'ի'],\n",
              " ['եւ', 'են'],\n",
              " ['եւ', 'և'],\n",
              " ['եւ', 'ի'],\n",
              " ['եւ', 'հետ'],\n",
              " ['ի', 'և'],\n",
              " ['ի', 'եւ'],\n",
              " ['ի', 'հետ'],\n",
              " ['ի', 'համար'],\n",
              " ['հետ', 'եւ'],\n",
              " ['հետ', 'ի'],\n",
              " ['հետ', 'համար'],\n",
              " ['հետ', 'այս'],\n",
              " ['համար', 'ի'],\n",
              " ['համար', 'հետ'],\n",
              " ['համար', 'այս'],\n",
              " ['համար', 'մասին'],\n",
              " ['այս', 'հետ'],\n",
              " ['այս', 'համար'],\n",
              " ['այս', 'մասին'],\n",
              " ['այս', 'ու'],\n",
              " ['մասին', 'համար'],\n",
              " ['մասին', 'այս'],\n",
              " ['մասին', 'ու'],\n",
              " ['մասին', 'այդ'],\n",
              " ['ու', 'այս'],\n",
              " ['ու', 'մասին'],\n",
              " ['ու', 'այդ'],\n",
              " ['ու', 'ին'],\n",
              " ['այդ', 'մասին'],\n",
              " ['այդ', 'ու'],\n",
              " ['այդ', 'ին'],\n",
              " ['այդ', 'էր'],\n",
              " ['ին', 'ու'],\n",
              " ['ին', 'այդ'],\n",
              " ['ին', 'էր'],\n",
              " ['ին', 'հհ'],\n",
              " ['էր', 'այդ'],\n",
              " ['էր', 'ին'],\n",
              " ['էր', 'հհ'],\n",
              " ['էր', 'իր'],\n",
              " ['հհ', 'ին'],\n",
              " ['հհ', 'էր'],\n",
              " ['հհ', 'իր'],\n",
              " ['հհ', 'այն'],\n",
              " ['իր', 'էր'],\n",
              " ['իր', 'հհ'],\n",
              " ['իր', 'այն'],\n",
              " ['իր', 'չի'],\n",
              " ['այն', 'հհ'],\n",
              " ['այն', 'իր'],\n",
              " ['այն', 'չի'],\n",
              " ['այն', 'թե'],\n",
              " ['չի', 'իր'],\n",
              " ['չի', 'այն'],\n",
              " ['չի', 'թե'],\n",
              " ['չի', 'մի'],\n",
              " ['թե', 'այն'],\n",
              " ['թե', 'չի'],\n",
              " ['թե', 'մի'],\n",
              " ['թե', 'նա'],\n",
              " ['մի', 'չի'],\n",
              " ['մի', 'թե'],\n",
              " ['մի', 'նա'],\n",
              " ['մի', 'եմ'],\n",
              " ['նա', 'թե'],\n",
              " ['նա', 'մի'],\n",
              " ['նա', 'եմ'],\n",
              " ['նա', 'ենք'],\n",
              " ['եմ', 'մի'],\n",
              " ['եմ', 'նա'],\n",
              " ['եմ', 'ենք'],\n",
              " ['եմ', 'պետք'],\n",
              " ['ենք', 'նա'],\n",
              " ['ենք', 'եմ'],\n",
              " ['ենք', 'պետք'],\n",
              " ['ենք', 'ոչ'],\n",
              " ['պետք', 'եմ'],\n",
              " ['պետք', 'ենք'],\n",
              " ['պետք', 'ոչ'],\n",
              " ['պետք', 'մեր'],\n",
              " ['ոչ', 'ենք'],\n",
              " ['ոչ', 'պետք'],\n",
              " ['ոչ', 'մեր'],\n",
              " ['ոչ', 'էլ'],\n",
              " ['մեր', 'պետք'],\n",
              " ['մեր', 'ոչ'],\n",
              " ['մեր', 'էլ'],\n",
              " ['մեր', 'կարող'],\n",
              " ['էլ', 'ոչ']]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "window_size = 2\n",
        "training_dataset = create_training_dataset(vocabulary, window_size)\n",
        "training_dataset[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RvoQJPdue-9I"
      },
      "outputs": [],
      "source": [
        "def random_batch(data, size, vocabulary):\n",
        "\n",
        "  if size > len(data):\n",
        "    raise ValueError(\"The size of the batch is greater than the size of the data.\")\n",
        "\n",
        "  random_index = np.random.choice(range(len(data)), size, replace=False)\n",
        "\n",
        "  random_inputs = []\n",
        "  random_labels = []\n",
        "  for i in random_index:\n",
        "    random_inputs.append(np.eye(len(vocabulary))[vocabulary.index(data[i][0])])  # input\n",
        "    random_labels.append(vocabulary.index(data[i][1]))  # context word\n",
        "\n",
        "  return random_inputs, random_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KLL5ZchWe-9I"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = random_batch(training_dataset,200, vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aMCVFIFye-9J"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ1aI3V3zU6w",
        "outputId": "36561e9f-e570-4abb-fd70-2881f0f76edc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 2500)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRzVXRPjzWop",
        "outputId": "bf1430ca-feb1-4cd5-e2a3-817b389556c1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200,)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qAprDyute-9J"
      },
      "outputs": [],
      "source": [
        "vocab_size = 200\n",
        "embedding_dim = 200\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=1),\n",
        "    tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AQVog0DxdOK",
        "outputId": "73e118bc-2a1c-4805-cd73-75a192f28390"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1, 200)            40000     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1, 200)            40200     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 80,200\n",
            "Trainable params: 80,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=200)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3yCFoJ9fxetp",
        "outputId": "8db4312d-62e3-4af7-e182-a4fcca941a3a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-3986025d7362>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-25-3a9d90273059>\", line 1, in <cell line: 1>\n      model.fit(X_train, y_train, epochs=10, batch_size=64)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 2078, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5660, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [500000,200] and labels shape [200]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_769]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k3ARryW8x2Gu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "10web_task",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}