{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D_6Q8-x2tZL"
      },
      "source": [
        "# Large scale text analysis with deep learning\n",
        "\n",
        "Today we're gonna apply the newly learned tools for the task of predicting job salary.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3342/media/salary%20prediction%20engine%20v2.png\" width=400px>\n",
        "\n",
        "_Special thanks to [Oleg Vasilev](https://github.com/Omrigan/) for the core assignment idea._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KriCJJwD2tZR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI54ffcX2tZT"
      },
      "source": [
        "### About the challenge\n",
        "For starters, let's download and unpack the data from [here](https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=0).\n",
        "\n",
        "You can also get it from [yadisk url](https://yadi.sk/d/vVEOWPFY3NruT7) the competition [page](https://www.kaggle.com/c/job-salary-prediction/data) (pick `Train_rev1.*`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMf1U2_s2tZU",
        "outputId": "c02f2d35-63c2-42ab-f986-754664c08029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    17    0    17    0     0     38      0 --:--:-- --:--:-- --:--:--    38\n",
            "100   299  100   299    0     0    373      0 --:--:-- --:--:-- --:--:--   373\n",
            "100  119M  100  119M    0     0  21.3M      0  0:00:05  0:00:05 --:--:-- 29.1M\n",
            "Train_rev1.csv\n"
          ]
        }
      ],
      "source": [
        "!curl -L https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1 -o Train_rev1.csv.tar.gz\n",
        "!tar -xvzf ./Train_rev1.csv.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO0m9iVd2tZW",
        "outputId": "cc526aa9-52a1-4d27-9d15-7a4976721209"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(244768, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlN97lET2tZX"
      },
      "source": [
        "One problem with salary prediction is that it's oddly distributed: there are many people who are paid standard salaries and a few that get tons o money. The distribution is fat-tailed on the right side, which is inconvenient for MSE minimization.\n",
        "\n",
        "There are several techniques to combat this: using a different loss function, predicting log-target instead of raw target or even replacing targets with their percentiles among all salaries in the training set. We gonna use logarithm for now.\n",
        "\n",
        "_You can read more [in the official description](https://www.kaggle.com/c/job-salary-prediction#description)._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "5s_h8Xj92tZX",
        "outputId": "00b0ddfd-8b0c-4a89-f6df-217233f4bdf0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArUAAAFfCAYAAABQlzQ4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABK3ElEQVR4nO3de1gU59k/8C8Hd8HDLqLCQkHFaEQUQVHXTdRXI2VVkkiDqRqqxKC+8oINrFGktWi0LRbjgUSUJiZi3kg99IomAQUJCsaIJyJRUPipwWKqC0aFVaKAML8/fJm6ARUUdhn4fq5rrsud596Ze57AzJ3hmWcsBEEQQEREREQkYZbmToCIiIiI6FmxqCUiIiIiyWNRS0RERESSx6KWiIiIiCSPRS0RERERSR6LWiIiIiKSPBa1RERERCR51uZOwJzq6upw9epVdOvWDRYWFuZOh4jaGUEQcPv2bTg7O8PSsn3eQ+B5lIhaW1PPpR26qL169SpcXV3NnQYRtXNXrlyBi4uLudNoFTyPEpGpPOlc2qGL2m7dugF40EkKhcLM2RBRe2MwGODq6iqea9ojnkeJqLU19VzaoYva+j+VKRQKnoyJqNW05z/L8zxKRKbypHNp+xzkRUREREQdCotaIiIiIpI8FrVEREREJHksaomIiIhI8ljUEhEREZHksaglIiIiIsljUUtEREREkseiloiIiIgkj0UtEREREUkei1oiIiIikjwWtUREREQkeSxqiYiIiEjyrM2dQEfQd2lqs79zebV/K2RCRERkfs29LvKaSE3BoraNYiFMRERE1HQcfkBEREREkseiloiIiIgkj0UtEREREUkei1oiIiIikjwWtUREREQkeSxqiYiIiEjyWNQSERERkeSxqCUiIiIiyWNRS0RERESSxzeKERER0VN7mjdgErUG3qklIjKhzZs3Y+jQoVAoFFAoFNBoNNi/f7/YPn78eFhYWBgtCxYsMNpGSUkJ/P390blzZzg4OGDx4sW4f/++UUxWVhaGDx8OuVyO/v37IykpqUEuCQkJ6Nu3L2xsbKBWq3HixIlWOWYiIlNgUUtEZEIuLi5YvXo1cnNzcerUKbz00kuYOnUqCgoKxJh58+bh2rVr4hIXFye21dbWwt/fH9XV1Th69Ci2bduGpKQkxMTEiDHFxcXw9/fHhAkTkJeXh4iICMydOxfp6elizM6dO6HT6bB8+XJ899138PLyglarRVlZmWk6goiohbGoJSIyoVdeeQVTpkzBgAED8Pzzz+Mvf/kLunbtimPHjokxnTt3hkqlEheFQiG2HThwAOfOncNnn30Gb29vTJ48GatWrUJCQgKqq6sBAImJiXBzc8PatWsxaNAghIeHY9q0aVi/fr24nXXr1mHevHmYM2cOPDw8kJiYiM6dO+OTTz4xXWcQEbUgFrVERGZSW1uLHTt2oLKyEhqNRly/fft29OzZE0OGDEF0dDR+/vlnsS0nJweenp5wdHQU12m1WhgMBvFub05ODnx9fY32pdVqkZOTAwCorq5Gbm6uUYylpSV8fX3FmEepqqqCwWAwWoiI2gI+KEZEZGJnz56FRqPBvXv30LVrV+zZswceHh4AgDfeeAN9+vSBs7Mzzpw5g6ioKBQVFeHzzz8HAOj1eqOCFoD4Wa/XPzbGYDDg7t27uHXrFmpraxuNKSwsfGzusbGxePfdd5/+4ImIWkmz79T++9//xu9+9zv06NEDtra28PT0xKlTp8R2QRAQExMDJycn2NrawtfXFxcuXDDaxs2bNxEUFASFQgE7OzuEhITgzp07RjFnzpzB2LFjYWNjA1dXV6MxZfV2794Nd3d32NjYwNPTE/v27Wvu4RARmdzAgQORl5eH48ePIzQ0FMHBwTh37hwAYP78+dBqtfD09ERQUBA+/fRT7NmzB5cuXTJz1g9ER0ejoqJCXK5cuWLulIiIADSzqL116xZefPFFdOrUCfv378e5c+ewdu1adO/eXYyJi4vD+++/j8TERBw/fhxdunSBVqvFvXv3xJigoCAUFBQgIyMDKSkpOHz4MObPny+2GwwG+Pn5oU+fPsjNzcWaNWuwYsUKfPjhh2LM0aNHMXPmTISEhOD06dMICAhAQEAA8vPzn6U/iIhanUwmQ//+/eHj44PY2Fh4eXkhPj6+0Vi1Wg0AuHjxIgBApVKhtLTUKKb+s0qlemyMQqGAra0tevbsCSsrq0Zj6rfxKHK5XJy5oX4hImoLmlXU/u1vf4Orqyu2bt2KUaNGwc3NDX5+fnjuuecAPLhLu2HDBixbtgxTp07F0KFD8emnn+Lq1avYu3cvAOD8+fNIS0vDli1boFarMWbMGHzwwQfYsWMHrl69CuDBeLLq6mp88sknGDx4MGbMmIHf//73WLdunZhLfHw8Jk2ahMWLF2PQoEFYtWoVhg8fjo0bN7ZQ1xARmUZdXR2qqqoabcvLywMAODk5AQA0Gg3Onj1rNEtBRkYGFAqFOIRBo9EgMzPTaDsZGRniuF2ZTAYfHx+jmLq6OmRmZhqN7SUikpJmFbVffvklRowYgddffx0ODg4YNmwYPvroI7G9uLgYer3e6OEDpVIJtVotPnyQk5MDOzs7jBgxQozx9fWFpaUljh8/LsaMGzcOMplMjNFqtSgqKsKtW7fEmMc9CNEYPuBAROYWHR2Nw4cP4/Llyzh79iyio6ORlZWFoKAgXLp0CatWrUJubi4uX76ML7/8ErNnz8a4ceMwdOhQAICfnx88PDwwa9YsfP/990hPT8eyZcsQFhYGuVwOAFiwYAF++OEHLFmyBIWFhdi0aRN27dqFyMhIMQ+dToePPvoI27Ztw/nz5xEaGorKykrMmTPHLP1CRPSsmlXU/vDDD9i8eTMGDBiA9PR0hIaG4ve//z22bdsG4D8PKTT28MHDDzA4ODgYtVtbW8Pe3v6JDzk8vI9HxdS3NyY2NhZKpVJcXF1dm3P4RETPrKysDLNnz8bAgQMxceJEnDx5Eunp6fj1r38NmUyGr7/+Gn5+fnB3d8eiRYsQGBiIr776Svy+lZUVUlJSYGVlBY1Gg9/97neYPXs2Vq5cKca4ubkhNTUVGRkZ8PLywtq1a7FlyxZotVoxZvr06XjvvfcQExMDb29v5OXlIS0trcF5lYhIKpo1+0FdXR1GjBiBv/71rwCAYcOGIT8/H4mJiQgODm6VBFtSdHQ0dDqd+NlgMLCwJSKT+vjjjx/Z5urqiuzs7Cduo0+fPk98MHb8+PE4ffr0Y2PCw8MRHh7+xP0REUlBs+7UOjk5iWO26g0aNAglJSUA/vOQwuMePlCpVA3eWHP//n3cvHnziQ85PLyPR8U87iEHPuBARERE1D41q6h98cUXUVRUZLTu//2//4c+ffoAePAnL5VKZfTwgcFgwPHjx8WHDzQaDcrLy5GbmyvGHDx4EHV1deJTvhqNBocPH0ZNTY0Yk5GRgYEDB4ozLTzpQQgiIiIi6jiaVdRGRkbi2LFj+Otf/4qLFy8iOTkZH374IcLCwgAAFhYWiIiIwJ///Gd8+eWXOHv2LGbPng1nZ2cEBAQAeHBnd9KkSZg3bx5OnDiBb7/9FuHh4ZgxYwacnZ0BPJh8XCaTISQkBAUFBdi5cyfi4+ONhg68/fbbSEtLw9q1a1FYWIgVK1bg1KlT/FMaERERUQfUrDG1I0eOxJ49exAdHY2VK1fCzc0NGzZsQFBQkBizZMkSVFZWYv78+SgvL8eYMWOQlpYGGxsbMWb79u0IDw/HxIkTYWlpicDAQLz//vtiu1KpxIEDBxAWFgYfHx/07NkTMTExRnPZvvDCC0hOTsayZcvwhz/8AQMGDMDevXsxZMiQZ+kPIiIiIpIgC0EQBHMnYS4GgwFKpRIVFRWtOr6279LUVtv2wy6v9jfJfoioaUx1jjGnjnCM9HimuMbx+taxNfU80+zX5BIRERERtTUsaomIiIhI8ljUEhEREZHkNetBMSIiImq/TPUMCFFr4J1aIiIiIpI8FrVEREREJHksaomIiIhI8ljUEhEREZHksaglIiIiIsljUUtEREREkseiloiIiIgkj0UtEREREUkei1oiIiIikjwWtUREREQkeSxqiYiIiEjyWNQSERERkeSxqCUiIiIiyWNRS0RERESSx6KWiIiIiCSPRS0RERERSR6LWiIiIiKSPBa1RERERCR5LGqJiIiISPJY1BIRERGR5LGoJSIyoc2bN2Po0KFQKBRQKBTQaDTYv3+/2H7v3j2EhYWhR48e6Nq1KwIDA1FaWmq0jZKSEvj7+6Nz585wcHDA4sWLcf/+faOYrKwsDB8+HHK5HP3790dSUlKDXBISEtC3b1/Y2NhArVbjxIkTrXLMRESmwKKWiMiEXFxcsHr1auTm5uLUqVN46aWXMHXqVBQUFAAAIiMj8dVXX2H37t3Izs7G1atX8dprr4nfr62thb+/P6qrq3H06FFs27YNSUlJiImJEWOKi4vh7++PCRMmIC8vDxEREZg7dy7S09PFmJ07d0Kn02H58uX47rvv4OXlBa1Wi7KyMtN1BhFRC7IQBEEwdxLmYjAYoFQqUVFRAYVC0Wr76bs0tdW2/bDLq/1Nsh8iapqmnmPs7e2xZs0aTJs2Db169UJycjKmTZsGACgsLMSgQYOQk5OD0aNHY//+/Xj55Zdx9epVODo6AgASExMRFRWF69evQyaTISoqCqmpqcjPzxf3MWPGDJSXlyMtLQ0AoFarMXLkSGzcuBEAUFdXB1dXVyxcuBBLly59ZK5VVVWoqqoyOkZXV9dWP4+SaZjqetVcvL51bE09l/JOLRGRmdTW1mLHjh2orKyERqNBbm4uampq4OvrK8a4u7ujd+/eyMnJAQDk5OTA09NTLGgBQKvVwmAwiHd7c3JyjLZRH1O/jerqauTm5hrFWFpawtfXV4x5lNjYWCiVSnFxdXV9tk4gImohLGqJiEzs7Nmz6Nq1K+RyORYsWIA9e/bAw8MDer0eMpkMdnZ2RvGOjo7Q6/UAAL1eb1TQ1rfXtz0uxmAw4O7du/jpp59QW1vbaEz9Nh4lOjoaFRUV4nLlypVmHz8RUWuwNncCREQdzcCBA5GXl4eKigr885//RHBwMLKzs82dVpPI5XLI5XJzp0FE1ACLWiIiE5PJZOjfvz8AwMfHBydPnkR8fDymT5+O6upqlJeXG92tLS0thUqlAgCoVKoGsxTUz47wcMwvZ0woLS2FQqGAra0trKysYGVl1WhM/TaIiKSGww+IiMysrq4OVVVV8PHxQadOnZCZmSm2FRUVoaSkBBqNBgCg0Whw9uxZo1kKMjIyoFAo4OHhIcY8vI36mPptyGQy+Pj4GMXU1dUhMzNTjCEikhreqSUiMqHo6GhMnjwZvXv3xu3bt5GcnIysrCykp6dDqVQiJCQEOp0O9vb2UCgUWLhwITQaDUaPHg0A8PPzg4eHB2bNmoW4uDjo9XosW7YMYWFh4rCABQsWYOPGjViyZAneeustHDx4ELt27UJq6n+ebNfpdAgODsaIESMwatQobNiwAZWVlZgzZ45Z+oWI6FmxqCUiMqGysjLMnj0b165dg1KpxNChQ5Geno5f//rXAID169fD0tISgYGBqKqqglarxaZNm8TvW1lZISUlBaGhodBoNOjSpQuCg4OxcuVKMcbNzQ2pqamIjIxEfHw8XFxcsGXLFmi1WjFm+vTpuH79OmJiYqDX6+Ht7Y20tLQGD48REUlFs4YfrFixAhYWFkaLu7u72M434RARPd7HH3+My5cvo6qqCmVlZfj666/FghYAbGxskJCQgJs3b6KyshKff/55g3Guffr0wb59+/Dzzz/j+vXreO+992BtbXyPYvz48Th9+jSqqqpw6dIlvPnmmw1yCQ8Px7/+9S9UVVXh+PHjUKvVrXLMRESm0OwxtYMHD8a1a9fE5ciRI2Ib34RDRERERObQ7KLW2toaKpVKXHr27AkAqKiowMcff4x169bhpZdego+PD7Zu3YqjR4/i2LFjAIADBw7g3Llz+Oyzz+Dt7Y3Jkydj1apVSEhIQHV1NYAHb8Zxc3PD2rVrMWjQIISHh2PatGlYv369mMO6deswb948zJkzBx4eHkhMTETnzp3xySeftESfEBEREZHENLuovXDhApydndGvXz8EBQWhpKQEACTxJpyqqioYDAajhYiIiIikr1lFrVqtRlJSEtLS0rB582YUFxdj7NixuH37tiTehMPXOxIRERG1T82a/WDy5Mniv4cOHQq1Wo0+ffpg165dsLW1bfHkWlp0dDR0Op342WAwsLAlIiIiagee6eULdnZ2eP7553Hx4kWoVCrxTTgP++WbcBp7g0192+Ni6t+E07Nnz6d+E45cLodCoTBaiIiIiEj6nqmovXPnDi5dugQnJye+CYeIiIiIzKZZRe0777yD7OxsXL58GUePHsVvfvMbWFlZYebMmUZvwjl06BByc3MxZ86cR74J5/vvv0d6enqjb8L54YcfsGTJEhQWFmLTpk3YtWsXIiMjxTx0Oh0++ugjbNu2DefPn0doaCjfhENERETUgTVrTO2PP/6ImTNn4saNG+jVqxfGjBmDY8eOoVevXgD4JhwiIiJqeX2Xpj456Bcur/ZvhUyoLbMQBEEwdxLmYjAYoFQqUVFR0arja5/ml/Fp8BeYqG0x1TnGnDrCMXYkprpemQKvie1HU88zzzSmloiIiIioLWBRS0RERESSx6KWiIiIiCSPRS0RERERSR6LWiIiIiKSPBa1RERERCR5LGqJiIiISPJY1BIRERGR5LGoJSIiIiLJY1FLRERERJLHopaIiIiIJI9FLRERERFJHotaIiIiIpI8FrVEREREJHksaomIiIhI8ljUEhEREZHksaglIiIiIsljUUtEREREkseilojIhGJjYzFy5Eh069YNDg4OCAgIQFFRkVHM+PHjYWFhYbQsWLDAKKakpAT+/v7o3LkzHBwcsHjxYty/f98oJisrC8OHD4dcLkf//v2RlJTUIJ+EhAT07dsXNjY2UKvVOHHiRIsfMxGRKbCoJSIyoezsbISFheHYsWPIyMhATU0N/Pz8UFlZaRQ3b948XLt2TVzi4uLEttraWvj7+6O6uhpHjx7Ftm3bkJSUhJiYGDGmuLgY/v7+mDBhAvLy8hAREYG5c+ciPT1djNm5cyd0Oh2WL1+O7777Dl5eXtBqtSgrK2v9jiAiamHW5k6AiKgjSUtLM/qclJQEBwcH5ObmYty4ceL6zp07Q6VSNbqNAwcO4Ny5c/j666/h6OgIb29vrFq1ClFRUVixYgVkMhkSExPh5uaGtWvXAgAGDRqEI0eOYP369dBqtQCAdevWYd68eZgzZw4AIDExEampqfjkk0+wdOnS1jh8IqJWwzu1RERmVFFRAQCwt7c3Wr99+3b07NkTQ4YMQXR0NH7++WexLScnB56ennB0dBTXabVaGAwGFBQUiDG+vr5G29RqtcjJyQEAVFdXIzc31yjG0tISvr6+YkxjqqqqYDAYjBYioraAd2qJiMykrq4OERERePHFFzFkyBBx/RtvvIE+ffrA2dkZZ86cQVRUFIqKivD5558DAPR6vVFBC0D8rNfrHxtjMBhw9+5d3Lp1C7W1tY3GFBYWPjLn2NhYvPvuu09/0ERErYRFLRGRmYSFhSE/Px9HjhwxWj9//nzx356ennBycsLEiRNx6dIlPPfcc6ZO00h0dDR0Op342WAwwNXV1YwZERE9wKKWiMgMwsPDkZKSgsOHD8PFxeWxsWq1GgBw8eJFPPfcc1CpVA1mKSgtLQUAcRyuSqUS1z0co1AoYGtrCysrK1hZWTUa86ixvAAgl8shl8ubdpBERCbEMbVERCYkCALCw8OxZ88eHDx4EG5ubk/8Tl5eHgDAyckJAKDRaHD27FmjWQoyMjKgUCjg4eEhxmRmZhptJyMjAxqNBgAgk8ng4+NjFFNXV4fMzEwxhohISninlojIhMLCwpCcnIwvvvgC3bp1E8fAKpVK2Nra4tKlS0hOTsaUKVPQo0cPnDlzBpGRkRg3bhyGDh0KAPDz84OHhwdmzZqFuLg46PV6LFu2DGFhYeJd1AULFmDjxo1YsmQJ3nrrLRw8eBC7du1CamqqmItOp0NwcDBGjBiBUaNGYcOGDaisrBRnQyAikhIWtUREJrR582YAD16w8LCtW7fizTffhEwmw9dffy0WmK6urggMDMSyZcvEWCsrK6SkpCA0NBQajQZdunRBcHAwVq5cKca4ubkhNTUVkZGRiI+Ph4uLC7Zs2SJO5wUA06dPx/Xr1xETEwO9Xg9vb2+kpaU1eHiMiEgKLARBEMydhLkYDAYolUpUVFRAoVC02n76Lk19cpCZXF7tb+4UiNotU51jzKkjHGNH0pavV83F61v70dTzDMfUEhEREZHksaglIiIiIsljUUtEREREkseiloiIiIgkj0UtEREREUkei1oiIiIikrxnKmpXr14NCwsLREREiOvu3buHsLAw9OjRA127dkVgYGCD1zCWlJTA398fnTt3hoODAxYvXoz79+8bxWRlZWH48OGQy+Xo378/kpKSGuw/ISEBffv2hY2NDdRqdYPXRhIRERFRx/DURe3Jkyfx97//XXzDTb3IyEh89dVX2L17N7Kzs3H16lW89tprYnttbS38/f1RXV2No0ePYtu2bUhKSkJMTIwYU1xcDH9/f0yYMAF5eXmIiIjA3LlzkZ6eLsbs3LkTOp0Oy5cvx3fffQcvLy9otVqj10YSERERUcfwVEXtnTt3EBQUhI8++gjdu3cX11dUVODjjz/GunXr8NJLL8HHxwdbt27F0aNHcezYMQDAgQMHcO7cOXz22Wfw9vbG5MmTsWrVKiQkJKC6uhoAkJiYCDc3N6xduxaDBg1CeHg4pk2bhvXr14v7WrduHebNm4c5c+bAw8MDiYmJ6Ny5Mz755JNH5l1VVQWDwWC0EBEREZH0PVVRGxYWBn9/f/j6+hqtz83NRU1NjdF6d3d39O7dGzk5OQCAnJwceHp6Gr2GUavVwmAwoKCgQIz55ba1Wq24jerqauTm5hrFWFpawtfXV4xpTGxsLJRKpbi4uro+zeETERERURtj3dwv7NixA9999x1OnjzZoE2v10Mmk8HOzs5ovaOjI/R6vRjzy/eK139+UozBYMDdu3dx69Yt1NbWNhpTWFj4yNyjo6Oh0+nEzwaDgYUtERG1S+3plbdETdGsovbKlSt4++23kZGRARsbm9bKqdXI5XLI5XJzp0FERERELaxZww9yc3NRVlaG4cOHw9raGtbW1sjOzsb7778Pa2trODo6orq6GuXl5UbfKy0thUqlAgCoVKoGsyHUf35SjEKhgK2tLXr27AkrK6tGY+q3QUREREQdR7OK2okTJ+Ls2bPIy8sTlxEjRiAoKEj8d6dOnZCZmSl+p6ioCCUlJdBoNAAAjUaDs2fPGs1SkJGRAYVCAQ8PDzHm4W3Ux9RvQyaTwcfHxyimrq4OmZmZYgwRERERdRzNGn7QrVs3DBkyxGhdly5d0KNHD3F9SEgIdDod7O3toVAosHDhQmg0GowePRoA4OfnBw8PD8yaNQtxcXHQ6/VYtmwZwsLCxKEBCxYswMaNG7FkyRK89dZbOHjwIHbt2oXU1P+MD9LpdAgODsaIESMwatQobNiwAZWVlZgzZ84zdQgRERERSU+zHxR7kvXr18PS0hKBgYGoqqqCVqvFpk2bxHYrKyukpKQgNDQUGo0GXbp0QXBwMFauXCnGuLm5ITU1FZGRkYiPj4eLiwu2bNkCrVYrxkyfPh3Xr19HTEwM9Ho9vL29kZaW1uDhMSIiIiJq/ywEQRDMnYS5GAwGKJVKVFRUQKFQtNp+2vITqJdX+5s7BaJ2y1TnGHPqCMcoVW352mMKvL61H009zzzTa3KJiIiIiNoCFrVEREREJHksaomIiIhI8ljUEhEREZHksaglIiIiIsljUUtEREREkseiloiIiIgkj0UtEREREUkei1oiIiIikjwWtUREREQkeSxqiYiIiEjyWNQSERERkeSxqCUiMqHY2FiMHDkS3bp1g4ODAwICAlBUVGQUc+/ePYSFhaFHjx7o2rUrAgMDUVpaahRTUlICf39/dO7cGQ4ODli8eDHu379vFJOVlYXhw4dDLpejf//+SEpKapBPQkIC+vbtCxsbG6jVapw4caLFj5mIyBRY1BIRmVB2djbCwsJw7NgxZGRkoKamBn5+fqisrBRjIiMj8dVXX2H37t3Izs7G1atX8dprr4nttbW18Pf3R3V1NY4ePYpt27YhKSkJMTExYkxxcTH8/f0xYcIE5OXlISIiAnPnzkV6eroYs3PnTuh0OixfvhzfffcdvLy8oNVqUVZWZprOICJqQRaCIAjmTsJcDAYDlEolKioqoFAoWm0/fZemttq2n9Xl1f7mToGo3WrKOeb69etwcHBAdnY2xo0bh4qKCvTq1QvJycmYNm0aAKCwsBCDBg1CTk4ORo8ejf379+Pll1/G1atX4ejoCABITExEVFQUrl+/DplMhqioKKSmpiI/P1/c14wZM1BeXo60tDQAgFqtxsiRI7Fx40YAQF1dHVxdXbFw4UIsXbq0xY6RzKMtX3tMgde39qOp5xneqSUiMqOKigoAgL29PQAgNzcXNTU18PX1FWPc3d3Ru3dv5OTkAABycnLg6ekpFrQAoNVqYTAYUFBQIMY8vI36mPptVFdXIzc31yjG0tISvr6+YkxjqqqqYDAYjBYioraARS0RkZnU1dUhIiICL774IoYMGQIA0Ov1kMlksLOzM4p1dHSEXq8XYx4uaOvb69seF2MwGHD37l389NNPqK2tbTSmfhuNiY2NhVKpFBdXV9fmHzgRUStgUUtEZCZhYWHIz8/Hjh07zJ1Kk0VHR6OiokJcrly5Yu6UiIgAANbmToCIqCMKDw9HSkoKDh8+DBcXF3G9SqVCdXU1ysvLje7WlpaWQqVSiTG/nKWgfnaEh2N+OWNCaWkpFAoFbG1tYWVlBSsrq0Zj6rfRGLlcDrlc3vwDJiJqZSxqiYhMSBAELFy4EHv27EFWVhbc3NyM2n18fNCpUydkZmYiMDAQAFBUVISSkhJoNBoAgEajwV/+8heUlZXBwcEBAJCRkQGFQgEPDw8xZt++fUbbzsjIELchk8ng4+ODzMxMBAQEAHgwHCIzMxPh4eGtdvz0dDr6Q19ETcGilojIhMLCwpCcnIwvvvgC3bp1E8evKpVK2NraQqlUIiQkBDqdDvb29lAoFFi4cCE0Gg1Gjx4NAPDz84OHhwdmzZqFuLg46PV6LFu2DGFhYeJd1AULFmDjxo1YsmQJ3nrrLRw8eBC7du1Caup/iiOdTofg4GCMGDECo0aNwoYNG1BZWYk5c+aYvmOIiJ4Ri1oiIhPavHkzAGD8+PFG67du3Yo333wTALB+/XpYWloiMDAQVVVV0Gq12LRpkxhrZWWFlJQUhIaGQqPRoEuXLggODsbKlSvFGDc3N6SmpiIyMhLx8fFwcXHBli1boNVqxZjp06fj+vXriImJgV6vh7e3N9LS0ho8PEZEJAWcp5bz1Jo7BaJ2qyPM4doRjrEtaMvXkbaK17f2g/PUEhEREVGHwaKWiIiIiCSPRS0RERERSR6LWiIiIiKSPBa1RERERCR5LGqJiIiISPJY1BIRERGR5LGoJSIiIiLJY1FLRERERJLHopaIiIiIJI9FLRERERFJXrOK2s2bN2Po0KFQKBRQKBTQaDTYv3+/2H7v3j2EhYWhR48e6Nq1KwIDA1FaWmq0jZKSEvj7+6Nz585wcHDA4sWLcf/+faOYrKwsDB8+HHK5HP3790dSUlKDXBISEtC3b1/Y2NhArVbjxIkTzTkUIiIiImpHrJsT7OLigtWrV2PAgAEQBAHbtm3D1KlTcfr0aQwePBiRkZFITU3F7t27oVQqER4ejtdeew3ffvstAKC2thb+/v5QqVQ4evQorl27htmzZ6NTp07461//CgAoLi6Gv78/FixYgO3btyMzMxNz586Fk5MTtFotAGDnzp3Q6XRITEyEWq3Ghg0boNVqUVRUBAcHhxbuIiIiIuoI+i5NbfZ3Lq/2b4VM6GlYCIIgPMsG7O3tsWbNGkybNg29evVCcnIypk2bBgAoLCzEoEGDkJOTg9GjR2P//v14+eWXcfXqVTg6OgIAEhMTERUVhevXr0MmkyEqKgqpqanIz88X9zFjxgyUl5cjLS0NAKBWqzFy5Ehs3LgRAFBXVwdXV1csXLgQS5cubXLuBoMBSqUSFRUVUCgUz9INj/U0vySmwl9GotZjqnOMOXWEY2wL2vJ1pK16musbi9q2qannmaceU1tbW4sdO3agsrISGo0Gubm5qKmpga+vrxjj7u6O3r17IycnBwCQk5MDT09PsaAFAK1WC4PBgIKCAjHm4W3Ux9Rvo7q6Grm5uUYxlpaW8PX1FWMepaqqCgaDwWghIiIiIulrdlF79uxZdO3aFXK5HAsWLMCePXvg4eEBvV4PmUwGOzs7o3hHR0fo9XoAgF6vNypo69vr2x4XYzAYcPfuXfz000+ora1tNKZ+G48SGxsLpVIpLq6urs09fCIiIiJqg5pd1A4cOBB5eXk4fvw4QkNDERwcjHPnzrVGbi0uOjoaFRUV4nLlyhVzp0RERERELaBZD4oBgEwmQ//+/QEAPj4+OHnyJOLj4zF9+nRUV1ejvLzc6G5taWkpVCoVAEClUjWYpaB+doSHY345Y0JpaSkUCgVsbW1hZWUFKyurRmPqt/Eocrkccrm8uYdMRERERG3cM89TW1dXh6qqKvj4+KBTp07IzMwU24qKilBSUgKNRgMA0Gg0OHv2LMrKysSYjIwMKBQKeHh4iDEPb6M+pn4bMpkMPj4+RjF1dXXIzMwUY4iIiIioY2nWndro6GhMnjwZvXv3xu3bt5GcnIysrCykp6dDqVQiJCQEOp0O9vb2UCgUWLhwITQaDUaPHg0A8PPzg4eHB2bNmoW4uDjo9XosW7YMYWFh4h3UBQsWYOPGjViyZAneeustHDx4ELt27UJq6n+eSNTpdAgODsaIESMwatQobNiwAZWVlZgzZ04Ldg0RERERSUWzitqysjLMnj0b165dg1KpxNChQ5Geno5f//rXAID169fD0tISgYGBqKqqglarxaZNm8TvW1lZISUlBaGhodBoNOjSpQuCg4OxcuVKMcbNzQ2pqamIjIxEfHw8XFxcsGXLFnGOWgCYPn06rl+/jpiYGOj1enh7eyMtLa3Bw2NERERE1DE88zy1UsZ5ajm/HlFr6ghzuHaEY2wL2vJ1pKPjdbT1tfo8tUREREREbQWLWiIiIiKSPBa1RERERCR5LGqJiIiISPJY1BIRERGR5LGoJSIiIiLJY1FLRERERJLHopaIyMQOHz6MV155Bc7OzrCwsMDevXuN2t98801YWFgYLZMmTTKKuXnzJoKCgqBQKGBnZ4eQkBDcuXPHKObMmTMYO3YsbGxs4Orqiri4uAa57N69G+7u7rCxsYGnpyf27dvX4sdLRGQKLGqJiEyssrISXl5eSEhIeGTMpEmTcO3aNXH5xz/+YdQeFBSEgoICZGRkICUlBYcPH8b8+fPFdoPBAD8/P/Tp0we5ublYs2YNVqxYgQ8//FCMOXr0KGbOnImQkBCcPn0aAQEBCAgIQH5+fssfNBFRK2vWa3KJiOjZTZ48GZMnT35sjFwuh0qlarTt/PnzSEtLw8mTJzFixAgAwAcffIApU6bgvffeg7OzM7Zv347q6mp88sknkMlkGDx4MPLy8rBu3Tqx+I2Pj8ekSZOwePFiAMCqVauQkZGBjRs3IjExsdF9V1VVoaqqSvxsMBiaffxERK2Bd2qJiNqgrKwsODg4YODAgQgNDcWNGzfEtpycHNjZ2YkFLQD4+vrC0tISx48fF2PGjRsHmUwmxmi1WhQVFeHWrVtijK+vr9F+tVotcnJyHplXbGwslEqluLi6urbI8RIRPSsWtUREbcykSZPw6aefIjMzE3/729+QnZ2NyZMno7a2FgCg1+vh4OBg9B1ra2vY29tDr9eLMY6OjkYx9Z+fFFPf3pjo6GhUVFSIy5UrV57tYImIWgiHHxARtTEzZswQ/+3p6YmhQ4fiueeeQ1ZWFiZOnGjGzB4Mi5DL5WbNgYioMbxTS0TUxvXr1w89e/bExYsXAQAqlQplZWVGMffv38fNmzfFcbgqlQqlpaVGMfWfnxTzqLG8RERtGYtaIqI27scff8SNGzfg5OQEANBoNCgvL0dubq4Yc/DgQdTV1UGtVosxhw8fRk1NjRiTkZGBgQMHonv37mJMZmam0b4yMjKg0Wha+5CIiFoci1oiIhO7c+cO8vLykJeXBwAoLi5GXl4eSkpKcOfOHSxevBjHjh3D5cuXkZmZialTp6J///7QarUAgEGDBmHSpEmYN28eTpw4gW+//Rbh4eGYMWMGnJ2dAQBvvPEGZDIZQkJCUFBQgJ07dyI+Ph46nU7M4+2330ZaWhrWrl2LwsJCrFixAqdOnUJ4eLjJ+4SI6FmxqCUiMrFTp05h2LBhGDZsGABAp9Nh2LBhiImJgZWVFc6cOYNXX30Vzz//PEJCQuDj44NvvvnGaCzr9u3b4e7ujokTJ2LKlCkYM2aM0Ry0SqUSBw4cQHFxMXx8fLBo0SLExMQYzWX7wgsvIDk5GR9++CG8vLzwz3/+E3v37sWQIUNM1xlERC2ED4oREZnY+PHjIQjCI9vT09OfuA17e3skJyc/Nmbo0KH45ptvHhvz+uuv4/XXX3/i/oiI2jreqSUiIiIiyWNRS0RERESSx+EHHVzfpanNir+82r+VMiEiIiJ6erxTS0RERESSx6KWiIiIiCSPRS0RERERSR6LWiIiIiKSPBa1RERERCR5nP2AiIjIxJo78wwRPRnv1BIRERGR5LGoJSIiIiLJY1FLRERERJLHopaIiIiIJI9FLRERERFJHotaIiIiIpI8FrVEREREJHksaomIiIhI8ppV1MbGxmLkyJHo1q0bHBwcEBAQgKKiIqOYe/fuISwsDD169EDXrl0RGBiI0tJSo5iSkhL4+/ujc+fOcHBwwOLFi3H//n2jmKysLAwfPhxyuRz9+/dHUlJSg3wSEhLQt29f2NjYQK1W48SJE805HCIiIiJqJ5pV1GZnZyMsLAzHjh1DRkYGampq4Ofnh8rKSjEmMjISX331FXbv3o3s7GxcvXoVr732mtheW1sLf39/VFdX4+jRo9i2bRuSkpIQExMjxhQXF8Pf3x8TJkxAXl4eIiIiMHfuXKSnp4sxO3fuhE6nw/Lly/Hdd9/By8sLWq0WZWVlz9IfRERERCRBFoIgCE/75evXr8PBwQHZ2dkYN24cKioq0KtXLyQnJ2PatGkAgMLCQgwaNAg5OTkYPXo09u/fj5dffhlXr16Fo6MjACAxMRFRUVG4fv06ZDIZoqKikJqaivz8fHFfM2bMQHl5OdLS0gAAarUaI0eOxMaNGwEAdXV1cHV1xcKFC7F06dJG862qqkJVVZX42WAwwNXVFRUVFVAoFE/bDU/Unl6HeHm1v7lTIJIMg8EApVLZ6ucYc+oIx9ga2tN1oaPjdbH1NfU880xjaisqKgAA9vb2AIDc3FzU1NTA19dXjHF3d0fv3r2Rk5MDAMjJyYGnp6dY0AKAVquFwWBAQUGBGPPwNupj6rdRXV2N3NxcoxhLS0v4+vqKMY2JjY2FUqkUF1dX12c5fCIiIiJqI566qK2rq0NERARefPFFDBkyBACg1+shk8lgZ2dnFOvo6Ai9Xi/GPFzQ1rfXtz0uxmAw4O7du/jpp59QW1vbaEz9NhoTHR2NiooKcbly5UrzD5yIiIiI2hzrp/1iWFgY8vPzceTIkZbMp1XJ5XLI5XJzp0FERERELeyp7tSGh4cjJSUFhw4dgouLi7hepVKhuroa5eXlRvGlpaVQqVRizC9nQ6j//KQYhUIBW1tb9OzZE1ZWVo3G1G+DiIiIiDqOZhW1giAgPDwce/bswcGDB+Hm5mbU7uPjg06dOiEzM1NcV1RUhJKSEmg0GgCARqPB2bNnjWYpyMjIgEKhgIeHhxjz8DbqY+q3IZPJ4OPjYxRTV1eHzMxMMYaIiIiIOo5mDT8ICwtDcnIyvvjiC3Tr1k0cv6pUKmFrawulUomQkBDodDrY29tDoVBg4cKF0Gg0GD16NADAz88PHh4emDVrFuLi4qDX67Fs2TKEhYWJQwMWLFiAjRs3YsmSJXjrrbdw8OBB7Nq1C6mp/3laVKfTITg4GCNGjMCoUaOwYcMGVFZWYs6cOS3VN0REREQkEc0qajdv3gwAGD9+vNH6rVu34s033wQArF+/HpaWlggMDERVVRW0Wi02bdokxlpZWSElJQWhoaHQaDTo0qULgoODsXLlSjHGzc0NqampiIyMRHx8PFxcXLBlyxZotVoxZvr06bh+/TpiYmKg1+vh7e2NtLS0Bg+PEREREVH790zz1EqdqeZXbE/zEXI+PqKm6whzuHaEY2wN7em60NHxutj6TDJPLRERNd/hw4fxyiuvwNnZGRYWFti7d69RuyAIiImJgZOTE2xtbeHr64sLFy4Yxdy8eRNBQUFQKBSws7NDSEgI7ty5YxRz5swZjB07FjY2NnB1dUVcXFyDXHbv3g13d3fY2NjA09MT+/bta/HjJSIyBRa1REQmVllZCS8vLyQkJDTaHhcXh/fffx+JiYk4fvw4unTpAq1Wi3v37okxQUFBKCgoQEZGBlJSUnD48GHMnz9fbDcYDPDz80OfPn2Qm5uLNWvWYMWKFfjwww/FmKNHj2LmzJkICQnB6dOnERAQgICAAKO3ORIRSQWHH3D4QbPwzyxETdeUc4yFhQX27NmDgIAAAA/u0jo7O2PRokV45513ADx4e6OjoyOSkpIwY8YMnD9/Hh4eHjh58iRGjBgBAEhLS8OUKVPw448/wtnZGZs3b8Yf//hH8aU4ALB06VLs3bsXhYWFAB48m1BZWYmUlBQxn9GjR8Pb2xuJiYktdozUUHu6LnR0vC62Pg4/ICKSoOLiYuj1eqPXgCuVSqjVaqPXjdvZ2YkFLQD4+vrC0tISx48fF2PGjRsnFrTAg9eNFxUV4datW2LM415J3piqqioYDAajhYioLWBRS0TUhtRPlfi414Dr9Xo4ODgYtVtbW8Pe3r5FXkn+uNeNx8bGQqlUiourq2tzD5GIqFU89WtyOyr+yYiIOrLo6GjodDrxs8FgYGFLRG0C79QSEbUh9a/6ftxrwFUqldFbGQHg/v37uHnzZou8kvxxrxuXy+VQKBRGCxFRW8CiloioDXFzc4NKpTJ6DbjBYMDx48eNXjdeXl6O3NxcMebgwYOoq6uDWq0WYw4fPoyamhoxJiMjAwMHDkT37t3FmMe9kpyISEpY1BIRmdidO3eQl5eHvLw8AA8eDsvLy0NJSQksLCwQERGBP//5z/jyyy9x9uxZzJ49G87OzuIMCYMGDcKkSZMwb948nDhxAt9++y3Cw8MxY8YMODs7AwDeeOMNyGQyhISEoKCgADt37kR8fLzR0IG3334baWlpWLt2LQoLC7FixQqcOnUK4eHhpu4SIqJnxjG1REQmdurUKUyYMEH8XF9oBgcHIykpCUuWLEFlZSXmz5+P8vJyjBkzBmlpabCxsRG/s337doSHh2PixIniq8nff/99sV2pVOLAgQMICwuDj48PevbsiZiYGKO5bF944QUkJydj2bJl+MMf/oABAwZg7969GDJkiAl6gYioZXGe2mbOr9jRHxTjfHxETdcR5nDtCMfYGjr6taQ94XWx9XGeWiIiIiLqMFjUEhEREZHksaglIiIiIsnjg2LULE8zDozjjYiIiKi18U4tEREREUkei1oiIiIikjwWtUREREQkeSxqiYiIiEjyWNQSERERkeSxqCUiIiIiyWNRS0RERESSx6KWiIiIiCSPRS0RERERSR6LWiIiIiKSPBa1RERERCR5LGqJiIiISPKszZ0AERERkVT1XZra7O9cXu3fCpkQ79QSERERkeSxqCUiIiIiyWNRS0RERESSx6KWiIiIiCSPRS0RERERSR6LWiIiIiKSvGYXtYcPH8Yrr7wCZ2dnWFhYYO/evUbtgiAgJiYGTk5OsLW1ha+vLy5cuGAUc/PmTQQFBUGhUMDOzg4hISG4c+eOUcyZM2cwduxY2NjYwNXVFXFxcQ1y2b17N9zd3WFjYwNPT0/s27evuYdDRERERO1As4vayspKeHl5ISEhodH2uLg4vP/++0hMTMTx48fRpUsXaLVa3Lt3T4wJCgpCQUEBMjIykJKSgsOHD2P+/Pliu8FggJ+fH/r06YPc3FysWbMGK1aswIcffijGHD16FDNnzkRISAhOnz6NgIAABAQEID8/v7mHREREREQSZyEIgvDUX7awwJ49exAQEADgwV1aZ2dnLFq0CO+88w4AoKKiAo6OjkhKSsKMGTNw/vx5eHh44OTJkxgxYgQAIC0tDVOmTMGPP/4IZ2dnbN68GX/84x+h1+shk8kAAEuXLsXevXtRWFgIAJg+fToqKyuRkpIi5jN69Gh4e3sjMTGxSfkbDAYolUpUVFRAoVA06TtPM8lyR8dJpqmjeppzjNR0hGNsDbyWdGy8LjZPU88zLTqmtri4GHq9Hr6+vuI6pVIJtVqNnJwcAEBOTg7s7OzEghYAfH19YWlpiePHj4sx48aNEwtaANBqtSgqKsKtW7fEmIf3Ux9Tv5/GVFVVwWAwGC1EREREJH0tWtTq9XoAgKOjo9F6R0dHsU2v18PBwcGo3draGvb29kYxjW3j4X08Kqa+vTGxsbFQKpXi4urq2txDJCIiIqI2yNrcCZhSdHQ0dDqd+NlgMLCwJSKiZ8KhBERtQ4sWtSqVCgBQWloKJycncX1paSm8vb3FmLKyMqPv3b9/Hzdv3hS/r1KpUFpaahRT//lJMfXtjZHL5ZDL5U9xZEREprNixQq8++67RusGDhwoPlNw7949LFq0CDt27EBVVRW0Wi02bdpk9NerkpIShIaG4tChQ+jatSuCg4MRGxsLa+v/nPazsrKg0+lQUFAAV1dXLFu2DG+++aZJjpGoI3ua/xHiONwna9HhB25ublCpVMjMzBTXGQwGHD9+HBqNBgCg0WhQXl6O3NxcMebgwYOoq6uDWq0WYw4fPoyamhoxJiMjAwMHDkT37t3FmIf3Ux9Tvx8iIikbPHgwrl27Ji5HjhwR2yIjI/HVV19h9+7dyM7OxtWrV/Haa6+J7bW1tfD390d1dTWOHj2Kbdu2ISkpCTExMWJMcXEx/P39MWHCBOTl5SEiIgJz585Fenq6SY+TiKilNPtO7Z07d3Dx4kXxc3FxMfLy8mBvb4/evXsjIiICf/7znzFgwAC4ubnhT3/6E5ydncUZEgYNGoRJkyZh3rx5SExMRE1NDcLDwzFjxgw4OzsDAN544w28++67CAkJQVRUFPLz8xEfH4/169eL+3377bfxX//1X1i7di38/f2xY8cOnDp1ymjaLyIiqbK2tm70L08VFRX4+OOPkZycjJdeegkAsHXrVgwaNAjHjh3D6NGjceDAAZw7dw5ff/01HB0d4e3tjVWrViEqKgorVqyATCZDYmIi3NzcsHbtWgAPzs1HjhzB+vXrodVqTXqsREQtodl3ak+dOoVhw4Zh2LBhAACdTodhw4aJdwCWLFmChQsXYv78+Rg5ciTu3LmDtLQ02NjYiNvYvn073N3dMXHiREyZMgVjxowxKkaVSiUOHDiA4uJi+Pj4YNGiRYiJiTGay/aFF15AcnIyPvzwQ3h5eeGf//wn9u7diyFDhjx1ZxARtRUXLlyAs7Mz+vXrh6CgIJSUlAAAcnNzUVNTYzT7i7u7O3r37m00y4ynp6fRcAStVguDwYCCggIxprkzyACcRYaI2q5m36kdP348Hje1rYWFBVauXImVK1c+Msbe3h7JycmP3c/QoUPxzTffPDbm9ddfx+uvv/74hImIJEatViMpKQkDBw7EtWvX8O6772Ls2LHIz88X5++2s7Mz+s4vZ5l52hlkDAYD7t69C1tb20Zzi42NbTDel4ioLehQsx8QEUnB5MmTxX8PHToUarUaffr0wa5dux5ZbJoKZ5EhoraqRR8UIyKilmdnZ4fnn38eFy9ehEqlQnV1NcrLy41iHp795VlmkFEoFI8tnOVyORQKhdFCRNQWsKglImrj7ty5g0uXLsHJyQk+Pj7o1KmT0ewvRUVFKCkpMZpl5uzZs0bTJ2ZkZEChUMDDw0OM4QwyRNSesKglImpj3nnnHWRnZ+Py5cs4evQofvOb38DKygozZ86EUqlESEgIdDodDh06hNzcXMyZMwcajQajR48GAPj5+cHDwwOzZs3C999/j/T0dCxbtgxhYWHiXN0LFizADz/8gCVLlqCwsBCbNm3Crl27EBkZac5DJyJ6ahxTS0TUxvz444+YOXMmbty4gV69emHMmDE4duwYevXqBQBYv349LC0tERgYaPTyhXpWVlZISUlBaGgoNBoNunTpguDgYKMHeN3c3JCamorIyEjEx8fDxcUFW7Zs4XReRCRZFsLjpjJo5wwGA5RKJSoqKpo8LoyvQzQNvjmF2oOnOcdITUc4xifhdYFMoSNfF5t6nuHwAyIiIiKSPBa1RERERCR5LGqJiIiISPJY1BIRERGR5LGoJSIiIiLJY1FLRERERJLHopaIiIiIJI9FLRERERFJHotaIiIiIpI8FrVEREREJHksaomIiIhI8ljUEhEREZHkWZs7AaLG9F2a2uzvXF7t3wqZEBERkRTwTi0RERERSR6LWiIiIiKSPBa1RERERCR5LGqJiIiISPL4oBi1G3y4jIiIqOPinVoiIiIikjwWtUREREQkeSxqiYiIiEjyWNQSERERkeTxQTEiIiKiNq65D0N3xAeheaeWiIiIiCSPd2qpQ+M0YERERO0D79QSERERkeSxqCUiIiIiyePwAyIiov/zNEOSiKhtYFFLRETtEgtUoo5F8kVtQkIC1qxZA71eDy8vL3zwwQcYNWqUudMiIpIMc5xHOT0REbU0SRe1O3fuhE6nQ2JiItRqNTZs2ACtVouioiI4ODiYOz0iojZPKudR3nUloiexEARBMHcST0utVmPkyJHYuHEjAKCurg6urq5YuHAhli5d2iC+qqoKVVVV4ueKigr07t0bV65cgUKhaNI+hyxPb5nkSbLy39WaOwWSCIPBAFdXV5SXl0OpVJo7nUaZ4zwK8FxK1Ba11etbk8+lgkRVVVUJVlZWwp49e4zWz549W3j11Vcb/c7y5csFAFy4cOFi0uXKlSsmOCs2H8+jXLhwkdLypHOpZIcf/PTTT6itrYWjo6PRekdHRxQWFjb6nejoaOh0OvFzXV0dbt68iR49esDCwkJcX/9/BM2989DesB/YB/XYDw80tx8EQcDt27fh7OxsguyarzXPo20df6Ybx35piH3SkKn7pKnnUskWtU9DLpdDLpcbrbOzs3tkvEKh4A8w2A8A+6Ae++GB5vRDWx128LSaex5t6/gz3Tj2S0Psk4ZM2SdNOZdK9uULPXv2hJWVFUpLS43Wl5aWQqVSmSkrIiLp4HmUiNoTyRa1MpkMPj4+yMzMFNfV1dUhMzMTGo3GjJkREUkDz6NE1J5IeviBTqdDcHAwRowYgVGjRmHDhg2orKzEnDlznmm7crkcy5cvb/Anto6G/cA+qMd+eKA99kNrnUfbuvb437IlsF8aYp801Fb7RNJTegHAxo0bxUnDvb298f7770OtVps7LSIiyeB5lIjaA8kXtUREREREkh1TS0RERERUj0UtEREREUkei1oiIiIikjwWtUREREQkeSxqfyEhIQF9+/aFjY0N1Go1Tpw4Ye6UmmzFihWwsLAwWtzd3cX2e/fuISwsDD169EDXrl0RGBjYYNL1kpIS+Pv7o3PnznBwcMDixYtx//59o5isrCwMHz4ccrkc/fv3R1JSUoNcTNWPhw8fxiuvvAJnZ2dYWFhg7969Ru2CICAmJgZOTk6wtbWFr68vLly4YBRz8+ZNBAUFQaFQwM7ODiEhIbhz545RzJkzZzB27FjY2NjA1dUVcXFxDXLZvXs33N3dYWNjA09PT+zbt6/ZubRWP7z55psNfjYmTZrUrvohNjYWI0eORLdu3eDg4ICAgAAUFRUZxbSl34Gm5EKt4/bt24iIiECfPn1ga2uLF154ASdPnjR3WibTEufN9uhJ/fL555/Dz89PfCV0Xl6eWfI0pcf1SU1NDaKiouDp6YkuXbrA2dkZs2fPxtWrV82XsECiHTt2CDKZTPjkk0+EgoICYd68eYKdnZ1QWlpq7tSaZPny5cLgwYOFa9euicv169fF9gULFgiurq5CZmamcOrUKWH06NHCCy+8ILbfv39fGDJkiODr6yucPn1a2Ldvn9CzZ08hOjpajPnhhx+Ezp07CzqdTjh37pzwwQcfCFZWVkJaWpoYY8p+3Ldvn/DHP/5R+PzzzwUAwp49e4zaV69eLSiVSmHv3r3C999/L7z66quCm5ubcPfuXTFm0qRJgpeXl3Ds2DHhm2++Efr37y/MnDlTbK+oqBAcHR2FoKAgIT8/X/jHP/4h2NraCn//+9/FmG+//VawsrIS4uLihHPnzgnLli0TOnXqJJw9e7ZZubRWPwQHBwuTJk0y+tm4efOmUYzU+0Gr1Qpbt24V8vPzhby8PGHKlClC7969hTt37ogxbel34Em5UOv57W9/K3h4eAjZ2dnChQsXhOXLlwsKhUL48ccfzZ2aSbTEebM9elK/fPrpp8K7774rfPTRRwIA4fTp02bJ05Qe1yfl5eWCr6+vsHPnTqGwsFDIyckRRo0aJfj4+JgtXxa1Dxk1apQQFhYmfq6trRWcnZ2F2NhYM2bVdMuXLxe8vLwabSsvLxc6deok7N69W1x3/vx5AYCQk5MjCMKDH15LS0tBr9eLMZs3bxYUCoVQVVUlCIIgLFmyRBg8eLDRtqdPny5otVrxs7n68Ze/cHV1dYJKpRLWrFkjrisvLxfkcrnwj3/8QxAEQTh37pwAQDh58qQYs3//fsHCwkL497//LQiCIGzatEno3r272AeCIAhRUVHCwIEDxc+//e1vBX9/f6N81Gq18N///d9NzqWlPKqonTp16iO/0x77oaysTAAgZGdni/tpK78DTcmFWsfPP/8sWFlZCSkpKUbrhw8fLvzxj380U1bm8zTnzY6gsfNoveLi4g5T1D7scX1S78SJEwIA4V//+pdpkvoFDj/4P9XV1cjNzYWvr6+4ztLSEr6+vsjJyTFjZs1z4cIFODs7o1+/fggKCkJJSQkAIDc3FzU1NUbH5+7ujt69e4vHl5OTA09PTzg6OooxWq0WBoMBBQUFYszD26iPqd9GW+rH4uJi6PV6o1yUSiXUarXRMdvZ2WHEiBFijK+vLywtLXH8+HExZty4cZDJZGKMVqtFUVERbt26JcY8rl+akktry8rKgoODAwYOHIjQ0FDcuHFDbGuP/VBRUQEAsLe3B9C2fgeakgu1jvv376O2thY2NjZG621tbXHkyBEzZdV2tIVzFUlXRUUFLCwsYGdnZ5b9s6j9Pz/99BNqa2uNLmYA4OjoCL1eb6asmketViMpKQlpaWnYvHkziouLMXbsWNy+fRt6vR4ymazBD9rDx6fX6xs9/vq2x8UYDAbcvXu3TfVj/f4el4ter4eDg4NRu7W1Nezt7VukXx5uf1IurWnSpEn49NNPkZmZib/97W/Izs7G5MmTUVtbK+bXnvqhrq4OERERePHFFzFkyBBx323ld6ApuVDr6NatGzQaDVatWoWrV6+itrYWn332GXJycnDt2jVzp2d25j5XkXTdu3cPUVFRmDlzJhQKhVlysDbLXqlVTJ48Wfz30KFDoVar0adPH+zatQu2trZmzIzMbcaMGeK/PT09MXToUDz33HPIysrCxIkTzZhZ6wgLC0N+fj7vvFGj/vd//xdvvfUWfvWrX8HKygrDhw/HzJkzkZuba+7UiCSppqYGv/3tbyEIAjZv3my2PHin9v/07NkTVlZWDZ4+Li0thUqlMlNWz8bOzg7PP/88Ll68CJVKherqapSXlxvFPHx8KpWq0eOvb3tcjEKhgK2tbZvqx/r9PS4XlUqFsrIyo/b79+/j5s2bLdIvD7c/KRdT6tevH3r27ImLFy+K+bWXfggPD0dKSgoOHToEFxcXcX1b+h1oSi7Uep577jlkZ2fjzp07uHLlCk6cOIGamhr069fP3KmZXVs7V1HbV1/Q/utf/0JGRobZ7tICLGpFMpkMPj4+yMzMFNfV1dUhMzMTGo3GjJk9vTt37uDSpUtwcnKCj48POnXqZHR8RUVFKCkpEY9Po9Hg7NmzRsVN/Q+oh4eHGPPwNupj6rfRlvrRzc0NKpXKKBeDwYDjx48bHXN5ebnRHZqDBw+irq4OarVajDl8+DBqamrEmIyMDAwcOBDdu3cXYx7XL03JxZR+/PFH3LhxA05OTgDaRz8IgoDw8HDs2bMHBw8ehJubm1F7W/odaEou1Pq6dOkCJycn3Lp1C+np6Zg6daq5UzK7tnauoratvqC9cOECvv76a/To0cO8CZnl8bQ2aseOHYJcLheSkpKEc+fOCfPnzxfs7OyMnoRuyxYtWiRkZWUJxcXFwrfffiv4+voKPXv2FMrKygRBeDCFUO/evYWDBw8Kp06dEjQajaDRaMTv109n5OfnJ+Tl5QlpaWlCr169Gp3OaPHixcL58+eFhISERqczMlU/3r59Wzh9+rRw+vRpAYCwbt064fTp0+KTl6tXrxbs7OyEL774Qjhz5owwderURqf0GjZsmHD8+HHhyJEjwoABA4ymsiovLxccHR2FWbNmCfn5+cKOHTuEzp07N5jKytraWnjvvfeE8+fPC8uXL290Kqsn5dIa/XD79m3hnXfeEXJycoTi4mLh66+/FoYPHy4MGDBAuHfvXrvph9DQUEGpVApZWVlGU5f9/PPPYkxb+h14Ui7UetLS0oT9+/cLP/zwg3DgwAHBy8tLUKvVQnV1tblTM4mWOG+2R0/qlxs3bginT58WUlNTBQDCjh07hNOnTwvXrl0zc+at53F9Ul1dLbz66quCi4uLkJeXZ3TefXiWHFNiUfsLH3zwgdC7d29BJpMJo0aNEo4dO2bulJps+vTpgpOTkyCTyYRf/epXwvTp04WLFy+K7Xfv3hX+53/+R+jevbvQuXNn4Te/+U2DX8bLly8LkydPFmxtbYWePXsKixYtEmpqaoxiDh06JHh7ewsymUzo16+fsHXr1ga5mKofDx06JABosAQHBwuC8GB6mj/96U+Co6OjIJfLhYkTJwpFRUVG27hx44Ywc+ZMoWvXroJCoRDmzJkj3L592yjm+++/F8aMGSPI5XLhV7/6lbB69eoGuezatUt4/vnnBZlMJgwePFhITU01am9KLq3RDz///LPg5+cn9OrVS+jUqZPQp08fYd68eQ3+J0Pq/dDY8QMw+vlsS78DTcmFWsfOnTuFfv36CTKZTFCpVEJYWJhQXl5u7rRMpiXOm+3Rk/pl69atjbYvX77crHm3psf1Sf3UZo0thw4dMku+FoIgCC1//5eIiIiIyHQ4ppaIiIiIJI9FLRERERFJHotaIiIiIpI8FrVEREREJHksaomIiIhI8ljUEhEREZHksaglIiIiIsljUUtEREREkseiloiIiIgkj0UtEREREUkei1oiIiIikrz/D9xHeguM97dyAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "\n",
        "plt.figure(figsize=[8, 4])\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(data[\"SalaryNormalized\"], bins=20);\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(data['Log1pSalary'], bins=20);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drR5eZfH2tZY"
      },
      "source": [
        "Our task is to predict one number, __Log1pSalary__.\n",
        "\n",
        "To do so, our model can access a number of features:\n",
        "* Free text: __`Title`__ and  __`FullDescription`__\n",
        "* Categorical: __`Category`__, __`Company`__, __`LocationNormalized`__, __`ContractType`__, and __`ContractTime`__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zcWW4Hd2tZY",
        "outputId": "311403bf-09f0-4b74-ecc9-b9144576fa94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                         0\n",
              "Title                      1\n",
              "FullDescription            0\n",
              "LocationRaw                0\n",
              "LocationNormalized         0\n",
              "ContractType          179326\n",
              "ContractTime           63905\n",
              "Company                32430\n",
              "Category                   0\n",
              "SalaryRaw                  0\n",
              "SalaryNormalized           0\n",
              "SourceName                 1\n",
              "Log1pSalary                0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data.isna().sum(axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "nwdOYLmr2tZZ",
        "outputId": "79ebf49a-c89f-4eb0-b171-d68d4b84c149"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Id                            Title  \\\n",
              "50913   68634402  Architectural Technician  Dubai   \n",
              "145474  70682136               Activity Assistant   \n",
              "243127  72690148             Maintenance Engineer   \n",
              "\n",
              "                                          FullDescription  \\\n",
              "50913   Our Client is a highly design focussed Archite...   \n",
              "145474  We believe that people should be looked after ...   \n",
              "243127  Global Automotive Manufacturer require a Maint...   \n",
              "\n",
              "                      LocationRaw LocationNormalized ContractType  \\\n",
              "50913   Staffordshire - Newcastle                 UK    full_time   \n",
              "145474  Birmingham, West Midlands         Birmingham    part_time   \n",
              "243127               Warwickshire       Warwickshire          NaN   \n",
              "\n",
              "       ContractTime                                 Company  \\\n",
              "50913     permanent                               CVbrowser   \n",
              "145474          NaN                                     NaN   \n",
              "243127    permanent  Michael Page   Engineering Manufacture   \n",
              "\n",
              "                          Category                 SalaryRaw  \\\n",
              "50913           Other/General Jobs             35000 - 45000   \n",
              "145474   Healthcare & Nursing Jobs     6.55 to 6.55 per hour   \n",
              "243127  Logistics & Warehouse Jobs  Circa 30K-35K+Shift All.   \n",
              "\n",
              "        SalaryNormalized      SourceName  Log1pSalary  \n",
              "50913              40000   cvbrowser.com    10.596660  \n",
              "145474             12576  careworx.co.uk     9.439625  \n",
              "243127             32500   jobsite.co.uk    10.389026  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-4ebc257e-0047-471d-bf78-2fa86929e920\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>FullDescription</th>\n",
              "      <th>LocationRaw</th>\n",
              "      <th>LocationNormalized</th>\n",
              "      <th>ContractType</th>\n",
              "      <th>ContractTime</th>\n",
              "      <th>Company</th>\n",
              "      <th>Category</th>\n",
              "      <th>SalaryRaw</th>\n",
              "      <th>SalaryNormalized</th>\n",
              "      <th>SourceName</th>\n",
              "      <th>Log1pSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50913</th>\n",
              "      <td>68634402</td>\n",
              "      <td>Architectural Technician  Dubai</td>\n",
              "      <td>Our Client is a highly design focussed Archite...</td>\n",
              "      <td>Staffordshire - Newcastle</td>\n",
              "      <td>UK</td>\n",
              "      <td>full_time</td>\n",
              "      <td>permanent</td>\n",
              "      <td>CVbrowser</td>\n",
              "      <td>Other/General Jobs</td>\n",
              "      <td>35000 - 45000</td>\n",
              "      <td>40000</td>\n",
              "      <td>cvbrowser.com</td>\n",
              "      <td>10.596660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145474</th>\n",
              "      <td>70682136</td>\n",
              "      <td>Activity Assistant</td>\n",
              "      <td>We believe that people should be looked after ...</td>\n",
              "      <td>Birmingham, West Midlands</td>\n",
              "      <td>Birmingham</td>\n",
              "      <td>part_time</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Healthcare &amp; Nursing Jobs</td>\n",
              "      <td>6.55 to 6.55 per hour</td>\n",
              "      <td>12576</td>\n",
              "      <td>careworx.co.uk</td>\n",
              "      <td>9.439625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243127</th>\n",
              "      <td>72690148</td>\n",
              "      <td>Maintenance Engineer</td>\n",
              "      <td>Global Automotive Manufacturer require a Maint...</td>\n",
              "      <td>Warwickshire</td>\n",
              "      <td>Warwickshire</td>\n",
              "      <td>NaN</td>\n",
              "      <td>permanent</td>\n",
              "      <td>Michael Page   Engineering Manufacture</td>\n",
              "      <td>Logistics &amp; Warehouse Jobs</td>\n",
              "      <td>Circa 30K-35K+Shift All.</td>\n",
              "      <td>32500</td>\n",
              "      <td>jobsite.co.uk</td>\n",
              "      <td>10.389026</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ebc257e-0047-471d-bf78-2fa86929e920')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-53848a37-322d-4651-aa32-69d6800e6f94\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-53848a37-322d-4651-aa32-69d6800e6f94')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-53848a37-322d-4651-aa32-69d6800e6f94 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ebc257e-0047-471d-bf78-2fa86929e920 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ebc257e-0047-471d-bf78-2fa86929e920');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\", 'SourceName']\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "data.dropna(subset=['Title'], inplace=True)\n",
        "\n",
        "data.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoCg1K9Y2tZa"
      },
      "source": [
        "### Preprocessing text data\n",
        "\n",
        "Just like last week, applying NLP to a problem begins from tokenization: splitting raw text into sequences of tokens (words, punctuation, etc).\n",
        "\n",
        "__Your task__ is to lowercase and tokenize all texts under `Title` and `FullDescription` columns. Store the tokenized data as a __space-separated__ string of tokens for performance reasons.\n",
        "\n",
        "It's okay to use nltk tokenizers. Assertions were designed for WordPunctTokenizer, slight deviations are okay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNBwUDHW2tZa",
        "outputId": "cdcea9db-8f40-43c4-f0b6-07d86a60d2df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw text:\n",
            "2         Mathematical Modeller / Simulation Analyst / O...\n",
            "100003    Strategy Education have been approached by a s...\n",
            "200003    Working within the financial sector, in the cl...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Raw text:\")\n",
        "print(data[\"FullDescription\"][2::100000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IunHnj4K2tZb"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "  if isinstance(text, float):\n",
        "    return None\n",
        "\n",
        "  text = text.lower()\n",
        "  tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2jUROM1D2tZb"
      },
      "outputs": [],
      "source": [
        "data['Title'] = data[\"Title\"].apply(preprocess_text)\n",
        "data['FullDescription'] = data[\"FullDescription\"].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptVJq0DY2tZb",
        "outputId": "054b9371-d0c3-4dc1-b05f-5abef37455d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                               engineering systems analyst\n",
              "1                                   stress engineer glasgow\n",
              "2                          modelling and simulation analyst\n",
              "3         engineering systems analyst / mathematical mod...\n",
              "4               pioneer , miser engineering systems analyst\n",
              "                                ...                        \n",
              "244763                                   teacher of science\n",
              "244764                  teacher of business studies and ict\n",
              "244765                                      english teacher\n",
              "244766                                      supply teachers\n",
              "244767                                           accountant\n",
              "Name: Title, Length: 244767, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data['Title']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjCqYEf22tZc"
      },
      "source": [
        "Now we can assume that our text is a space-separated list of tokens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Unjs6pD2tZc",
        "outputId": "bf21e8be-c087-4e61-9ef7-209cada9ae9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100003    strategy education have been approached by a s...\n",
            "200003    working within the financial sector , in the c...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWqW6omM2tZd"
      },
      "source": [
        "Not all words are equally useful. Some of them are typos or rare words that are only present a few times.\n",
        "\n",
        "Let's count how many times is each word present in the data so that we can build a \"white list\" of known words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xf0PKZev2tZd"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n",
        "def count_tokens(titles, full_descriptions):\n",
        "\n",
        "  token_counts = collections.Counter()\n",
        "  for title in titles:\n",
        "    if title is not None:\n",
        "      tokens = title.split()\n",
        "      for token in tokens:\n",
        "        token_counts[token] += 1\n",
        "  for full_description in full_descriptions:\n",
        "    if full_description is not None:\n",
        "      tokens = full_description.split()\n",
        "      for token in tokens:\n",
        "        token_counts[token] += 1\n",
        "  return token_counts\n",
        "\n",
        "token_counts = count_tokens(data['Title'], data['FullDescription'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06HH9WAu2tZd",
        "outputId": "89057f56-a105-4e0c-c891-95ce682e8a41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique tokens : 202704\n",
            "('and', 2657383)\n",
            "('.', 2523211)\n",
            "(',', 2318603)\n",
            "('the', 2080989)\n",
            "('to', 2019882)\n",
            "...\n",
            "('stephanietraveltraderecruitmnt', 1)\n",
            "('ruabon', 1)\n",
            "('lowehays', 1)\n",
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "LOnd2Gvh2tZe",
        "outputId": "1edddf51-f22a-4898-bafa-34b9b6ae093f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGwCAYAAABy28W7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAopElEQVR4nO3dfXRV1YH+8Scv5IYACS+RhEhCEAQJYqJ5wSgVolmTBoZR+jLYxWBgHDo6cYSmYmE5JW1HC4MOZcZ1La1rIc4aLcgaRVsQx4nBCEXyAkFoEEQBsypJQCRv0gSS/fujP4/e8iIXbnL3yf1+1rprcc/Z2WffjeQ+7rP3PmHGGCMAAABLhAe7AQAAAF9FOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsEpksBvgr+7ubn3yyScaNGiQwsLCgt0cAABwGYwxam1tVVJSksLDLz024rpw8sknnyg5OTnYzQAAAFegvr5eI0eOvGQZ14WTQYMGSfrzh4uNjQ1yawAAwOVoaWlRcnKy8z1+Ka4JJ16vV16vV11dXZKk2NhYwgkAAC5zOVMywtz2bJ2WlhbFxcWpubmZcAIAgEv48/3Nah0AAGAVwgkAALAK4QQAAFiFcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWIVwAgAArOKacOL1epWWlqbs7OxgNwUAAPQgnkr8F1KXbP7aMkdXzAj4dQEA6Mt4KjEAAHAtwgkAALAK4QQAAFiFcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWIVwAgAArEI4AQAAViGcAAAAqxBOAACAVQgnAADAKpHBuGhqaqpiY2MVHh6uIUOGqLy8PBjNAAAAFgpKOJGk3//+9xo4cGCwLg8AACzFbR0AAGAVv8NJRUWFZs6cqaSkJIWFhWnTpk3nlfF6vUpNTVV0dLQmT56syspKn/NhYWGaOnWqsrOz9cILL1xx4wEAQN/jdzhpb29Xenq6vF7vBc9v2LBBJSUlKi0t1e7du5Wenq6CggI1NTU5ZbZv366amhq99tpr+vnPf6733nvvyj8BAADoU/wOJ4WFhXr88cc1a9asC55ftWqVFixYoPnz5ystLU1r1qxRTEyM1q5d65S59tprJUkjRozQ9OnTtXv37oter6OjQy0tLT4vAADQdwV0zklnZ6dqamqUn5//5QXCw5Wfn6+dO3dK+vPIS2trqySpra1Nb731liZOnHjROpcvX664uDjnlZycHMgmAwAAywQ0nJw8eVJdXV1KSEjwOZ6QkKCGhgZJUmNjo6ZMmaL09HTdeuutuu+++5SdnX3ROpcuXarm5mbnVV9fH8gmAwAAy/T6UuLrrrtOe/fuvezyHo9HHo+nB1sEAABsEtCRk/j4eEVERKixsdHneGNjoxITE6+qbq/Xq7S0tEuOsgAAAPcLaDiJiopSZmamysrKnGPd3d0qKytTbm7uVdVdXFysuro6VVVVXW0zAQCAxfy+rdPW1qbDhw87748cOaLa2loNHTpUKSkpKikpUVFRkbKyspSTk6PVq1ervb1d8+fPD2jDAQBA3+R3OKmurlZeXp7zvqSkRJJUVFSkdevWafbs2Tpx4oSWLVumhoYGZWRkaOvWredNkgUAALiQMGOMCXYjLofX65XX61VXV5cOHTqk5uZmxcbGBvw6qUs2f22ZoytmBPy6AAD0ZS0tLYqLi7us72/XPFuHOScAAIQG14QTAAAQGggnAADAKoQTAABgFdeEEzZhAwAgNLgmnDAhFgCA0OCacAIAAEID4QQAAFiFcAIAAKzimnDChFgAAEKDa8IJE2IBAAgNrgknAAAgNBBOAACAVQgnAADAKoQTAABgFdeEE1brAAAQGlwTTlitAwBAaHBNOAEAAKGBcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCquCSfscwIAQGhwTThhnxMAAEKDa8IJAAAIDYQTAABgFcIJAACwCuEEAABYhXACAACsQjgBAABWIZwAAACruCacsAkbAAChwTXhhE3YAAAIDa4JJwAAIDQQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWIVwAgAArEI4AQAAViGcAAAAqxBOAACAVQgnAADAKoQTAABgFdeEE55KDABAaHBNOOGpxAAAhAbXhBMAABAaCCcAAMAqhBMAAGAVwgkAALAK4QQAAFiFcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWIVwAgAArEI4AQAAViGcAAAAqxBOAACAVYIWTj7//HONGjVKjzzySLCaAAAALBS0cPLEE0/o1ltvDdblAQCApYISTj744AO9//77KiwsDMblAQCAxfwOJxUVFZo5c6aSkpIUFhamTZs2nVfG6/UqNTVV0dHRmjx5siorK33OP/LII1q+fPkVNxoAAPRdfoeT9vZ2paeny+v1XvD8hg0bVFJSotLSUu3evVvp6ekqKChQU1OTJOnVV1/VuHHjNG7cuMu6XkdHh1paWnxeAACg74r09wcKCwsveTtm1apVWrBggebPny9JWrNmjTZv3qy1a9dqyZIlevfdd7V+/Xpt3LhRbW1tOnv2rGJjY7Vs2bIL1rd8+XL99Kc/9beZAADApQI656Szs1M1NTXKz8//8gLh4crPz9fOnTsl/Tls1NfX6+jRo3rqqae0YMGCiwYTSVq6dKmam5udV319fSCbDAAALOP3yMmlnDx5Ul1dXUpISPA5npCQoPfff/+K6vR4PPJ4PIFoHgAAcIGAhhN/zZs377LLer1eeb1edXV19VyDAABA0AX0tk58fLwiIiLU2Njoc7yxsVGJiYlXVXdxcbHq6upUVVV1VfUAAAC7BTScREVFKTMzU2VlZc6x7u5ulZWVKTc3N5CXAgAAfZTft3Xa2tp0+PBh5/2RI0dUW1uroUOHKiUlRSUlJSoqKlJWVpZycnK0evVqtbe3O6t3AAAALsXvcFJdXa28vDznfUlJiSSpqKhI69at0+zZs3XixAktW7ZMDQ0NysjI0NatW8+bJOsv5pwAABAawowxJtiN8EdLS4vi4uLU3Nys2NjYgNefumTz15Y5umJGwK8LAEBf5s/3d9Ae/AcAAHAhhBMAAGAVwgkAALCKa8KJ1+tVWlqasrOzg90UAADQg1wTTtiEDQCA0OCacAIAAEID4QQAAFiFcAIAAKzimnDChFgAAEKDa8IJE2IBAAgNrgknAAAgNBBOAACAVQgnAADAKoQTAABgFdeEE1brAAAQGlwTTlitAwBAaHBNOAEAAKGBcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCquCSfscwIAQGhwTThhnxMAAEKDa8IJAAAIDYQTAABgFcIJAACwCuEEAABYhXACAACsQjgBAABWIZwAAACrEE4AAIBVXBNO2CEWAIDQ4Jpwwg6xAACEBteEEwAAEBoIJwAAwCqEEwAAYBXCCQAAsArhBAAAWIVwAgAArBIZ7Aa4UeqSzV9b5uiKGb3QEgAA+h5GTgAAgFUIJwAAwCqEEwAAYBXCCQAAsArhBAAAWMU14YSnEgMAEBpcE054KjEAAKHBNeEEAACEBsIJAACwCuEEAABYhXACAACsQjgBAABWIZwAAACrEE4AAIBVCCcAAMAqhBMAAGAVwgkAALAK4QQAAFiFcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCqRvX3B06dPKz8/X+fOndO5c+e0cOFCLViwoLeb0eNSl2z+2jJHV8zohZYAAOAuvR5OBg0apIqKCsXExKi9vV033nijvvWtb2nYsGG93RQAAGChXr+tExERoZiYGElSR0eHjDEyxvR2MwAAgKX8DicVFRWaOXOmkpKSFBYWpk2bNp1Xxuv1KjU1VdHR0Zo8ebIqKyt9zp8+fVrp6ekaOXKkFi9erPj4+Cv+AAAAoG/xO5y0t7crPT1dXq/3guc3bNigkpISlZaWavfu3UpPT1dBQYGampqcMoMHD9bevXt15MgRvfjii2psbLzo9To6OtTS0uLzAgAAfZff4aSwsFCPP/64Zs2adcHzq1at0oIFCzR//nylpaVpzZo1iomJ0dq1a88rm5CQoPT0dL3zzjsXvd7y5csVFxfnvJKTk/1tMgAAcJGAzjnp7OxUTU2N8vPzv7xAeLjy8/O1c+dOSVJjY6NaW1slSc3NzaqoqND48eMvWufSpUvV3NzsvOrr6wPZZAAAYJmArtY5efKkurq6lJCQ4HM8ISFB77//viTp2LFj+v73v+9MhP3nf/5nTZo06aJ1ejweeTyeQDYTAABYrNeXEufk5Ki2tra3LwsAAFwioLd14uPjFRERcd4E18bGRiUmJl5V3V6vV2lpacrOzr6qegAAgN0CGk6ioqKUmZmpsrIy51h3d7fKysqUm5t7VXUXFxerrq5OVVVVV9tMAABgMb9v67S1tenw4cPO+yNHjqi2tlZDhw5VSkqKSkpKVFRUpKysLOXk5Gj16tVqb2/X/PnzA9pwAADQN/kdTqqrq5WXl+e8LykpkSQVFRVp3bp1mj17tk6cOKFly5apoaFBGRkZ2rp163mTZAEAAC4kzLhk73iv1yuv16uuri4dOnRIzc3Nio2NDfh1LueBfYHCg/8AAKGipaVFcXFxl/X93evP1rlSzDkBACA0uCacAACA0EA4AQAAVnFNOGGfEwAAQoNrJsR+wZ8JNVeiNyfEXg4mzQIA+oI+OSEWAACEBsIJAACwCuEEAABYhXACAACs4ppwwmodAABCg2vCCTvEAgAQGlwTTgAAQGggnAAAAKsQTgAAgFUig90AXNrl7FjLLrIAgL7ENSMnrNYBACA0uCacsFoHAIDQ4JpwAgAAQgPhBAAAWIVwAgAArEI4AQAAViGcAAAAq7gmnLCUGACA0OCacMJSYgAAQoNrwgkAAAgNhBMAAGAVwgkAALAKD/7rA3g4IACgL2HkBAAAWIVwAgAArEI4AQAAViGcAAAAq7gmnLBDLAAAocE14YQdYgEACA2uCScAACA0EE4AAIBVCCcAAMAq7BAbIthFFgDgFoycAAAAqxBOAACAVQgnAADAKoQTAABgFcIJAACwCuEEAABYhaXEcLDcGABgA0ZOAACAVVwTTngqMQAAocE14YSnEgMAEBqYcwK/MC8FANDTXDNyAgAAQgPhBAAAWIVwAgAArMKcEwQc81IAAFeDkRMAAGAVwgkAALAK4QQAAFiFcAIAAKxCOAEAAFZhtQ6CghU9AICLYeQEAABYhXACAACswm0dWItbPwAQmhg5AQAAViGcAAAAq/R6OKmvr9e0adOUlpamm266SRs3buztJgAAAIv1+pyTyMhIrV69WhkZGWpoaFBmZqamT5+uAQMG9HZTAACAhXo9nIwYMUIjRoyQJCUmJio+Pl6nTp0inOCKMGkWAPoev8NJRUWFnnzySdXU1Oj48eN65ZVXdM899/iU8Xq9evLJJ9XQ0KD09HQ9/fTTysnJOa+umpoadXV1KTk5+Yo/APB1CDAA4C5+zzlpb29Xenq6vF7vBc9v2LBBJSUlKi0t1e7du5Wenq6CggI1NTX5lDt16pTuu+8+/frXv76ylgMAgD7J75GTwsJCFRYWXvT8qlWrtGDBAs2fP1+StGbNGm3evFlr167VkiVLJEkdHR265557tGTJEt12222XvF5HR4c6Ojqc9y0tLf42GQAAuEhAV+t0dnaqpqZG+fn5X14gPFz5+fnauXOnJMkYo3nz5unOO+/U3Llzv7bO5cuXKy4uznlxCwgAgL4toOHk5MmT6urqUkJCgs/xhIQENTQ0SJJ27NihDRs2aNOmTcrIyFBGRob27dt30TqXLl2q5uZm51VfXx/IJgMAAMv0+mqdKVOmqLu7+7LLezweeTyeHmwRwKRZALBJQEdO4uPjFRERocbGRp/jjY2NSkxMvKq6vV6v0tLSlJ2dfVX1AAAAuwU0nERFRSkzM1NlZWXOse7ubpWVlSk3N/eq6i4uLlZdXZ2qqqqutpkAAMBift/WaWtr0+HDh533R44cUW1trYYOHaqUlBSVlJSoqKhIWVlZysnJ0erVq9Xe3u6s3gEAALgUv8NJdXW18vLynPclJSWSpKKiIq1bt06zZ8/WiRMntGzZMjU0NCgjI0Nbt249b5IsAADAhYQZY0ywG3E5vF6vvF6vurq6dOjQITU3Nys2Njbg17mciZHAxTBpFgAurKWlRXFxcZf1/d3rTyW+Usw5AQAgNPT6UmKgL2NJMgBcPdeMnAAAgNBAOAEAAFZxTThhEzYAAEKDa+acFBcXq7i42JntC/RlgZq7whwYAG7kmpETAAAQGlwzcgL0FYHaS4c9eQD0VYycAAAAq7gmnDAhFgCA0OCacMIOsQAAhAbXhBMAABAaCCcAAMAqhBMAAGAVwgkAALCKa8IJq3UAAAgNYcYYE+xG+OOL7eubm5sVGxsb8PrZ2Ao4H1vcA7ha/nx/s0MsgK/VV5/R01c/F+B2hBMAfRKjoIB7EU4A9JpABQZGM4C+zTUTYgEAQGggnAAAAKsQTgAAgFVcM+fE6/XK6/Wqq6sr2E0BAB+s+gECyzXhpLi4WMXFxc46aQChq6+uxCHkAH/GbR0AAGAVwgkAALAK4QQAAFiFcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCqu2YSNHWIBu/XVjdEA9D7XhBN2iAXgZoQ34PK5JpwAAPB1eARA30A4AQAX4csXoYAJsQAAwCqEEwAAYBXCCQAAsArhBAAAWIVwAgAArMJqHQC4BPYn6R30M76KcAIAfUygvugvZ0kyS5vRE7itAwAArMLICQCgR7nxlg0jQsHlmpETr9ertLQ0ZWdnB7spAACgB7kmnBQXF6uurk5VVVXBbgoAAOhBrgknAAAgNBBOAACAVZgQCwC4IDdOZO1NTJrtOYycAAAAqzByAgBAD2F05cowcgIAAKxCOAEAAFYhnAAAAKsw5wQAAMuF2twVRk4AAIBVCCcAAMAqhBMAAGAVwgkAALAKE2IBACGFbfntx8gJAACwCuEEAABYhds6AAAEUW/fZnLDnilBGTmZNWuWhgwZou985zvBuDwAALBYUMLJwoUL9V//9V/BuDQAALBcUMLJtGnTNGjQoGBcGgAAWM7vcFJRUaGZM2cqKSlJYWFh2rRp03llvF6vUlNTFR0drcmTJ6uysjIQbQUAACHA73DS3t6u9PR0eb3eC57fsGGDSkpKVFpaqt27dys9PV0FBQVqamq6ogZ2dHSopaXF5wUAAPouv1frFBYWqrCw8KLnV61apQULFmj+/PmSpDVr1mjz5s1au3atlixZ4ncDly9frp/+9Kd+/xwAAKGkL20uF9A5J52dnaqpqVF+fv6XFwgPV35+vnbu3HlFdS5dulTNzc3Oq76+PlDNBQAAFgroPicnT55UV1eXEhISfI4nJCTo/fffd97n5+dr7969am9v18iRI7Vx40bl5uZesE6PxyOPxxPIZgIAAIsFZRO2//u//wvGZQEAgAsE9LZOfHy8IiIi1NjY6HO8sbFRiYmJV1W31+tVWlqasrOzr6oeAABgt4CGk6ioKGVmZqqsrMw51t3drbKysovetrlcxcXFqqurU1VV1dU2EwAAWMzv2zptbW06fPiw8/7IkSOqra3V0KFDlZKSopKSEhUVFSkrK0s5OTlavXq12tvbndU7AAAAl+J3OKmurlZeXp7zvqSkRJJUVFSkdevWafbs2Tpx4oSWLVumhoYGZWRkaOvWredNkgUAALiQMGOMCXYjLofX65XX61VXV5cOHTqk5uZmxcbGBvw6fWmdOAAAV6Innkrc0tKiuLi4y/r+Dsqzda4Ec04AAAgNrgknAAAgNBBOAACAVVwTTtjnBACA0OCacMKcEwAAQoNrwgkAAAgNhBMAAGCVoDz472p8sS1LS0tLj9Tf3fF5j9QLAIBb9MR37Bd1Xs72aq4LJ62trZKk5OTkILcEAIC+KW51z9Xd2tqquLi4S5ZxzQ6xX+ju7tYnn3yiQYMGKSwsLKB1t7S0KDk5WfX19T2y+yz+jH7uHfRz76Cfewf93Ht6qq+NMWptbVVSUpLCwy89q8R1Iyfh4eEaOXJkj14jNjaW//h7Af3cO+jn3kE/9w76uff0RF9/3YjJF5gQCwAArEI4AQAAViGcfIXH41Fpaak8Hk+wm9Kn0c+9g37uHfRz76Cfe48Nfe26CbEAAKBvY+QEAABYhXACAACsQjgBAABWIZwAAACrEE7+P6/Xq9TUVEVHR2vy5MmqrKwMdpOstXz5cmVnZ2vQoEEaPny47rnnHh08eNCnzJ/+9CcVFxdr2LBhGjhwoL797W+rsbHRp8zHH3+sGTNmKCYmRsOHD9fixYt17tw5nzLbtm3TLbfcIo/Ho7Fjx2rdunU9/fGstWLFCoWFhWnRokXOMfo5cP74xz/q7/7u7zRs2DD1799fkyZNUnV1tXPeGKNly5ZpxIgR6t+/v/Lz8/XBBx/41HHq1CnNmTNHsbGxGjx4sO6//361tbX5lHnvvff0jW98Q9HR0UpOTtbKlSt75fPZoKurSz/+8Y81evRo9e/fX2PGjNG//uu/+jxrhX72X0VFhWbOnKmkpCSFhYVp06ZNPud7s083btyoG264QdHR0Zo0aZK2bNlyZR/KwKxfv95ERUWZtWvXmj/84Q9mwYIFZvDgwaaxsTHYTbNSQUGBee6558z+/ftNbW2tmT59uklJSTFtbW1OmQceeMAkJyebsrIyU11dbW699VZz2223OefPnTtnbrzxRpOfn2/27NljtmzZYuLj483SpUudMh999JGJiYkxJSUlpq6uzjz99NMmIiLCbN26tVc/rw0qKytNamqquemmm8zChQud4/RzYJw6dcqMGjXKzJs3z+zatct89NFH5o033jCHDx92yqxYscLExcWZTZs2mb1795q/+Zu/MaNHjzZnzpxxynzzm9806enp5t133zXvvPOOGTt2rPne977nnG9ubjYJCQlmzpw5Zv/+/eY3v/mN6d+/v/nVr37Vq583WJ544gkzbNgw87vf/c4cOXLEbNy40QwcOND8x3/8h1OGfvbfli1bzGOPPWZefvllI8m88sorPud7q0937NhhIiIizMqVK01dXZ35l3/5F9OvXz+zb98+vz8T4cQYk5OTY4qLi533XV1dJikpySxfvjyIrXKPpqYmI8m8/fbbxhhjTp8+bfr162c2btzolDlw4ICRZHbu3GmM+fM/pvDwcNPQ0OCU+eUvf2liY2NNR0eHMcaYRx991EycONHnWrNnzzYFBQU9/ZGs0traaq6//nrz5ptvmqlTpzrhhH4OnB/96EdmypQpFz3f3d1tEhMTzZNPPukcO336tPF4POY3v/mNMcaYuro6I8lUVVU5ZV5//XUTFhZm/vjHPxpjjHnmmWfMkCFDnL7/4trjx48P9Eey0owZM8zf//3f+xz71re+ZebMmWOMoZ8D4S/DSW/26d/+7d+aGTNm+LRn8uTJ5h//8R/9/hwhf1uns7NTNTU1ys/Pd46Fh4crPz9fO3fuDGLL3KO5uVmSNHToUElSTU2Nzp4969OnN9xwg1JSUpw+3blzpyZNmqSEhASnTEFBgVpaWvSHP/zBKfPVOr4oE2p/L8XFxZoxY8Z5fUE/B85rr72mrKwsffe739Xw4cN1880369lnn3XOHzlyRA0NDT79FBcXp8mTJ/v09eDBg5WVleWUyc/PV3h4uHbt2uWUueOOOxQVFeWUKSgo0MGDB/XZZ5/19McMuttuu01lZWU6dOiQJGnv3r3avn27CgsLJdHPPaE3+zSQv0tCPpycPHlSXV1dPr+8JSkhIUENDQ1BapV7dHd3a9GiRbr99tt14403SpIaGhoUFRWlwYMH+5T9ap82NDRcsM+/OHepMi0tLTpz5kxPfBzrrF+/Xrt379by5cvPO0c/B85HH32kX/7yl7r++uv1xhtv6MEHH9TDDz+s559/XtKXfXWp3xMNDQ0aPny4z/nIyEgNHTrUr7+PvmzJkiW69957dcMNN6hfv366+eabtWjRIs2ZM0cS/dwTerNPL1bmSvrcdU8lhl2Ki4u1f/9+bd++PdhN6XPq6+u1cOFCvfnmm4qOjg52c/q07u5uZWVl6ec//7kk6eabb9b+/fu1Zs0aFRUVBbl1fcdLL72kF154QS+++KImTpyo2tpaLVq0SElJSfQzfIT8yEl8fLwiIiLOW+HQ2NioxMTEILXKHR566CH97ne/U3l5uUaOHOkcT0xMVGdnp06fPu1T/qt9mpiYeME+/+LcpcrExsaqf//+gf441qmpqVFTU5NuueUWRUZGKjIyUm+//bb+8z//U5GRkUpISKCfA2TEiBFKS0vzOTZhwgR9/PHHkr7sq0v9nkhMTFRTU5PP+XPnzunUqVN+/X30ZYsXL3ZGTyZNmqS5c+fqBz/4gTMySD8HXm/26cXKXEmfh3w4iYqKUmZmpsrKypxj3d3dKisrU25ubhBbZi9jjB566CG98soreuuttzR69Gif85mZmerXr59Pnx48eFAff/yx06e5ubnat2+fzz+IN998U7Gxsc6XRG5urk8dX5QJlb+Xu+66S/v27VNtba3zysrK0pw5c5w/08+Bcfvtt5+3HP7QoUMaNWqUJGn06NFKTEz06aeWlhbt2rXLp69Pnz6tmpoap8xbb72l7u5uTZ482SlTUVGhs2fPOmXefPNNjR8/XkOGDOmxz2eLzz//XOHhvl87ERER6u7ulkQ/94Te7NOA/i7xewptH7R+/Xrj8XjMunXrTF1dnfn+979vBg8e7LPCAV968MEHTVxcnNm2bZs5fvy48/r888+dMg888IBJSUkxb731lqmurja5ubkmNzfXOf/FEte/+qu/MrW1tWbr1q3mmmuuueAS18WLF5sDBw4Yr9cbcktc/9JXV+sYQz8HSmVlpYmMjDRPPPGE+eCDD8wLL7xgYmJizH//9387ZVasWGEGDx5sXn31VfPee++Zu++++4LLMW+++Waza9cus337dnP99df7LMc8ffq0SUhIMHPnzjX79+8369evNzExMX12ietfKioqMtdee62zlPjll1828fHx5tFHH3XK0M/+a21tNXv27DF79uwxksyqVavMnj17zLFjx4wxvdenO3bsMJGRkeapp54yBw4cMKWlpSwlvlpPP/20SUlJMVFRUSYnJ8e8++67wW6StSRd8PXcc885Zc6cOWP+6Z/+yQwZMsTExMSYWbNmmePHj/vUc/ToUVNYWGj69+9v4uPjzQ9/+ENz9uxZnzLl5eUmIyPDREVFmeuuu87nGqHoL8MJ/Rw4v/3tb82NN95oPB6PueGGG8yvf/1rn/Pd3d3mxz/+sUlISDAej8fcdddd5uDBgz5lPv30U/O9733PDBw40MTGxpr58+eb1tZWnzJ79+41U6ZMMR6Px1x77bVmxYoVPf7ZbNHS0mIWLlxoUlJSTHR0tLnuuuvMY4895rM8lX72X3l5+QV/JxcVFRljerdPX3rpJTNu3DgTFRVlJk6caDZv3nxFnynMmK9szQcAABBkIT/nBAAA2IVwAgAArEI4AQAAViGcAAAAqxBOAACAVQgnAADAKoQTAABgFcIJAACwCuEEQK+YNm2aFi1aFOxmAHABwgkQAtasWaNBgwbp3LlzzrG2tjb169dP06ZN8ym7bds2hYWF6cMPP+zlVtohNTVVq1evDnYzgJBGOAFCQF5entra2lRdXe0ce+edd5SYmKhdu3bpT3/6k3O8vLxcKSkpGjNmjN/XMcb4BCAAuBKEEyAEjB8/XiNGjNC2bducY9u2bdPdd9+t0aNH69133/U5npeXJ0nq6OjQww8/rOHDhys6OlpTpkxRVVWVT9mwsDC9/vrryszMlMfj0fbt29Xe3q777rtPAwcO1IgRI/Tv//7vl9XO3/72t8rOzlZ0dLTi4+M1a9Ys59xnn32m++67T0OGDFFMTIwKCwv1wQcfOOd/8pOfKCMjw6e+1atXKzU11Xk/b9483XPPPXrqqac0YsQIDRs2TMXFxc5j4KdNm6Zjx47pBz/4gcLCwhQWFiZJOnbsmGbOnKkhQ4ZowIABmjhxorZs2XJZnwmA/wgnQIjIy8tTeXm58768vFzTpk3T1KlTneNnzpzRrl27nHDy6KOP6n/+53/0/PPPa/fu3Ro7dqwKCgp06tQpn7qXLFmiFStW6MCBA7rpppu0ePFivf3223r11Vf1v//7v9q2bZt27959yfZt3rxZs2bN0vTp07Vnzx6VlZUpJyfHOT9v3jxVV1frtdde086dO2WM0fTp051gcbnKy8v14Ycfqry8XM8//7zWrVundevWSZJefvlljRw5Uj/72c90/PhxHT9+XJJUXFysjo4OVVRUaN++ffq3f/s3DRw40K/rAvDDFT3LGIDrPPvss2bAgAHm7NmzpqWlxURGRpqmpibz4osvmjvuuMMYY0xZWZmRZI4dO2ba2tpMv379zAsvvODU0dnZaZKSkszKlSuNMV8+qn3Tpk1OmdbWVhMVFWVeeukl59inn35q+vfvbxYuXHjR9uXm5po5c+Zc8NyhQ4eMJLNjxw7n2MmTJ03//v2d65SWlpr09HSfn/vFL35hRo0a5bwvKioyo0aNMufOnXOOffe73zWzZ8923o8aNcr84he/8Kln0qRJ5ic/+clF2w4gsBg5AULEtGnT1N7erqqqKr3zzjsaN26crrnmGk2dOtWZd7Jt2zZdd911SklJ0YcffqizZ8/q9ttvd+ro16+fcnJydODAAZ+6s7KynD9/+OGH6uzs1OTJk51jQ4cO1fjx4y/ZvtraWt11110XPHfgwAFFRkb61Dls2DCNHz/+vLZ8nYkTJyoiIsJ5P2LECDU1NV3yZx5++GE9/vjjuv3221VaWqr33nvPr2sC8A/hBAgRY8eO1ciRI1VeXq7y8nJNnTpVkpSUlKTk5GT9/ve/V3l5ue68806/6x4wYMBVt69///5X9fPh4eEyxvgcu9Atn379+vm8DwsLU3d39yXr/od/+Ad99NFHmjt3rvbt26esrCw9/fTTV9VeABdHOAFCSF5enrZt26Zt27b5LCG+44479Prrr6uystKZbzJmzBhFRUVpx44dTrmzZ8+qqqpKaWlpF73GmDFj1K9fP+3atcs59tlnn+nQoUOXbNtNN92ksrKyC56bMGGCzp0751Pnp59+qoMHDzptueaaa9TQ0OATUGpray95zQuJiopSV1fXeceTk5P1wAMP6OWXX9YPf/hDPfvss37XDeDyRAa7AQB6T15enrM65YuRE0maOnWqHnroIXV2djrhZMCAAXrwwQe1ePFiDR06VCkpKVq5cqU+//xz3X///Re9xsCBA3X//fdr8eLFGjZsmIYPH67HHntM4eGX/n+h0tJS3XXXXRozZozuvfdenTt3Tlu2bNGPfvQjXX/99br77ru1YMEC/epXv9KgQYO0ZMkSXXvttbr77rsl/fm21YkTJ7Ry5Up95zvf0datW/X6668rNjbWrz5KTU1VRUWF7r33Xnk8HsXHx2vRokUqLCzUuHHj9Nlnn6m8vFwTJkzwq14Al4+REyCE5OXl6cyZMxo7dqwSEhKc41OnTlVra6uz5PgLK1as0Le//W3NnTtXt9xyiw4fPqw33nhDQ4YMueR1nnzySX3jG9/QzJkzlZ+frylTpigzM/OSPzNt2jRt3LhRr732mjIyMnTnnXeqsrLSOf/cc88pMzNTf/3Xf63c3FwZY7RlyxbnNs2ECRP0zDPPyOv1Kj09XZWVlXrkkUf87qOf/exnOnr0qMaMGaNrrrlGktTV1aXi4mJNmDBB3/zmNzVu3Dg988wzftcN4PKEmb+8SQsAABBEjJwAAACrEE4AAIBVCCcAAMAqhBMAAGAVwgkAALAK4QQAAFiFcAIAAKxCOAEAAFYhnAAAAKsQTgAAgFUIJwAAwCr/D8TpBdlbYfmmAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Let's see how many words are there for each count\n",
        "plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
        "plt.xlabel(\"Word counts\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrHbeRa92tZe"
      },
      "source": [
        "Now filter tokens a list of all tokens that occur at least 10 times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "a8lc13H62tZf"
      },
      "outputs": [],
      "source": [
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "def filter_tokens(token_counts, min_count):\n",
        "  tokens = []\n",
        "  for token, count in token_counts.items():\n",
        "    if count >= min_count:\n",
        "      tokens.append(token)\n",
        "  return tokens\n",
        "\n",
        "tokens = filter_tokens(token_counts, min_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjM1CCyr2tZf",
        "outputId": "8504280c-b1db-4dc2-f1f2-34843c828098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 34158\n",
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw_SrLWt2tZf"
      },
      "source": [
        "Build an inverse token index: a dictionary from token(string) to it's index in `tokens` (int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LeouZxTS2tZg"
      },
      "outputs": [],
      "source": [
        "token_to_id = {}\n",
        "for i, token in enumerate(tokens):\n",
        "    token_to_id[token] = i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7l9Cszt2tZg",
        "outputId": "fc17ceb7-28b6-42ec-ede2-6045801471b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI7dgQtW2tZg"
      },
      "source": [
        "And finally, let's use the vocabulary you've built to map text lines into neural network-digestible matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "A0M-Da0b2tZh"
      },
      "outputs": [],
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "\n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "\n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvQBajZw2tZh",
        "outputId": "c2591c05-4a8c-425d-cbf1-8ba0c7d1c4ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "year 3 teacher northampton\n",
            "senior associate employment solutions\n",
            "\n",
            "Matrix:\n",
            "[[10807 30161  2166     1]\n",
            " [33946   565 30401 21284]\n",
            " [27645  2866 10672 28662]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSgH2Y_W2tZh"
      },
      "source": [
        "Now let's  encode the categirical data we have.\n",
        "\n",
        "As usual, we shall use one-hot encoding for simplicity. Kudos if you use more advanced encodings: tf-idf, pretrained w2v etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "7THJuybt2tZi",
        "outputId": "20bc1394-a75d-476b-eb6f-e6f892457ffe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*collections.Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcEy8VlO2tZi"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwR21IKW2tZi",
        "outputId": "e9c232ff-1536-4057-d8e7-942d1e546405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size =  195813\n",
            "Validation size =  48954\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZhM7fmSv2tZk"
      },
      "outputs": [],
      "source": [
        "def make_batch(data, max_len=None, word_dropout=0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "\n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "\n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "\n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XoBKLEY2tZk",
        "outputId": "50ab5e1e-b1ef-4db5-e75f-6bcec14f7279"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Title': array([[23234,  9075,     1,     1,     1,     1,     1],\n",
              "        [27645, 29019, 10804,     1,     1,     1,     1],\n",
              "        [ 7574, 16690, 10804, 18371,   158,  3958,  8418]], dtype=int32),\n",
              " 'FullDescription': array([[ 2142, 11425, 21956, 14220,  2596, 12587,   982, 23234,  9075,\n",
              "         31100],\n",
              "        [30847, 16451,  2142, 11425,   158,  4510, 20918, 26621,   158,\n",
              "          7859],\n",
              "        [ 7574, 16690, 10804, 18371,   158,  3958,  8418,   158, 20610,\n",
              "           158]], dtype=int32),\n",
              " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " 'Log1pSalary': array([10.308986, 10.657283, 11.042938], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "make_batch(data_train[:3], max_len=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlg_qCc42tZl"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our basic model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndJcL_7j2taA"
      },
      "source": [
        "This clearly doesn't fit into keras' __Sequential__ interface. To build such a network, one will have to use __[Keras Functional API](https://keras.io/models/model/)__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nCR-g-7b2taB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.layers as L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uanpXcc12taB"
      },
      "outputs": [],
      "source": [
        "def build_model(n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=128):\n",
        "    \"\"\" Build a model that maps three data sources to a single linear output: predicted log1p(salary) \"\"\"\n",
        "\n",
        "    l_title = L.Input(shape=[None], name=\"Title\")\n",
        "    l_descr = L.Input(shape=[None], name=\"FullDescription\")\n",
        "    l_categ = L.Input(shape=[n_cat_features], name=\"Categorical\")\n",
        "\n",
        "    if l_title is not None:\n",
        "        f_title = tf.expand_dims(l_title, -1)\n",
        "        f_title = L.LSTM(hid_size)(f_title)\n",
        "        f_title = L.Dropout(0.2)(f_title)\n",
        "    else:\n",
        "        f_title = None\n",
        "\n",
        "    f_descr = L.LSTM(hid_size)(tf.expand_dims(l_descr,-1))\n",
        "    x = L.Concatenate()([f_title, f_descr, l_categ])\n",
        "\n",
        "    x = L.Dense(128)(x)\n",
        "    x = L.LeakyReLU()(x)\n",
        "\n",
        "    output_layer = L.Dense(1)(x)\n",
        "    model = keras.models.Model(inputs=[l_title, l_descr, l_categ], outputs=[output_layer])\n",
        "    model.compile('adam', 'mean_squared_error', metrics=['mean_absolute_error'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lWnW3gz2taC",
        "outputId": "6cda17b6-769f-40fd-9d35-9e92f82074a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Title (InputLayer)             [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " tf.expand_dims (TFOpLambda)    (None, None, 1)      0           ['Title[0][0]']                  \n",
            "                                                                                                  \n",
            " FullDescription (InputLayer)   [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 128)          66560       ['tf.expand_dims[0][0]']         \n",
            "                                                                                                  \n",
            " tf.expand_dims_1 (TFOpLambda)  (None, None, 1)      0           ['FullDescription[0][0]']        \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 128)          0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 128)          66560       ['tf.expand_dims_1[0][0]']       \n",
            "                                                                                                  \n",
            " Categorical (InputLayer)       [(None, 3936)]       0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 4192)         0           ['dropout[0][0]',                \n",
            "                                                                  'lstm_1[0][0]',                 \n",
            "                                                                  'Categorical[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          536704      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            129         ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 669,953\n",
            "Trainable params: 669,953\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py:639: UserWarning: Input dict contained keys ['Log1pSalary'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 5s 17ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py:639: UserWarning: Input dict contained keys ['Log1pSalary'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        }
      ],
      "source": [
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "dummy_pred = model.predict(make_batch(data_train[:100]))\n",
        "dummy_loss = model.train_on_batch(make_batch(data_train[:100]), data_train['Log1pSalary'][:100])[0]\n",
        "assert dummy_pred.shape == (100, 1)\n",
        "assert len(np.unique(dummy_pred)) > 20, \"model returns suspiciously few unique outputs. Check your initialization\"\n",
        "assert np.ndim(dummy_loss) == 0 and 0. <= dummy_loss <= 250., \"make sure you minimize MSE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpgHU5wl2taC"
      },
      "source": [
        "#### Training and evaluation\n",
        "\n",
        "As usual, we gonna feed our model with random minibatches of data.\n",
        "\n",
        "As we train, we want to monitor not only loss function, which is computed in log-space, but also the actual error measured in dollars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dyei76t62taC"
      },
      "outputs": [],
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "\n",
        "        if not cycle: break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsml5l_L2taD"
      },
      "source": [
        "### Model training\n",
        "\n",
        "We can now fit our model the usual minibatch way. The interesting part is that we train on an infinite stream of minibatches, produced by `iterate_minibatches` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "jWLW4pn12taE"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "epochs = 100\n",
        "steps_per_epoch = (len(data_train) - 1) // batch_size + 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "checkpoint_path = \"training/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)"
      ],
      "metadata": {
        "id": "RAAKFjp_U_Au"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_freq=steps_per_epoch)\n",
        "model_1 = build_model()\n",
        "\n",
        "model_1.fit(iterate_minibatches(data_train, batch_size, cycle=True, word_dropout=0.05),\n",
        "                    epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
        "\n",
        "                    validation_data=iterate_minibatches(data_val, batch_size, cycle=True),\n",
        "                    validation_steps=data_val.shape[0] // batch_size, callbacks = [callback, cp_callback]\n",
        "                   )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0ozlTo7OBa4",
        "outputId": "2f586809-eab0-43cb-8998-cf3d40e09dee"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "764/765 [============================>.] - ETA: 0s - loss: 1.1512 - mean_absolute_error: 0.4868\n",
            "Epoch 1: saving model to training/cp-0001.ckpt\n",
            "765/765 [==============================] - 95s 118ms/step - loss: 1.1501 - mean_absolute_error: 0.4866 - val_loss: 0.1418 - val_mean_absolute_error: 0.2914\n",
            "Epoch 2/100\n",
            "764/765 [============================>.] - ETA: 0s - loss: 0.1455 - mean_absolute_error: 0.2964\n",
            "Epoch 2: saving model to training/cp-0002.ckpt\n",
            "765/765 [==============================] - 73s 96ms/step - loss: 0.1455 - mean_absolute_error: 0.2964 - val_loss: 0.1403 - val_mean_absolute_error: 0.2913\n",
            "Epoch 3/100\n",
            "764/765 [============================>.] - ETA: 0s - loss: 0.1418 - mean_absolute_error: 0.2923\n",
            "Epoch 3: saving model to training/cp-0003.ckpt\n",
            "765/765 [==============================] - 75s 98ms/step - loss: 0.1418 - mean_absolute_error: 0.2923 - val_loss: 0.1397 - val_mean_absolute_error: 0.2899\n",
            "Epoch 4/100\n",
            "764/765 [============================>.] - ETA: 0s - loss: 0.1440 - mean_absolute_error: 0.2943\n",
            "Epoch 4: saving model to training/cp-0004.ckpt\n",
            "765/765 [==============================] - 74s 97ms/step - loss: 0.1440 - mean_absolute_error: 0.2944 - val_loss: 0.1422 - val_mean_absolute_error: 0.2916\n",
            "Epoch 5/100\n",
            "764/765 [============================>.] - ETA: 0s - loss: 0.1448 - mean_absolute_error: 0.2956\n",
            "Epoch 5: saving model to training/cp-0005.ckpt\n",
            "765/765 [==============================] - 73s 95ms/step - loss: 0.1448 - mean_absolute_error: 0.2956 - val_loss: 0.1418 - val_mean_absolute_error: 0.2915\n",
            "Epoch 6/100\n",
            "764/765 [============================>.] - ETA: 0s - loss: 0.1434 - mean_absolute_error: 0.2938\n",
            "Epoch 6: saving model to training/cp-0006.ckpt\n",
            "765/765 [==============================] - 74s 97ms/step - loss: 0.1434 - mean_absolute_error: 0.2938 - val_loss: 0.1408 - val_mean_absolute_error: 0.2912\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa42c2bd360>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_metrics(model, data, batch_size=batch_size, name=\"\", **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    for batch_x, batch_y in iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw):\n",
        "        batch_pred = model.predict(batch_x)[:, 0]\n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    return squared_error, abs_error\n",
        "\n",
        "print_metrics(model_1, data_train, name='Train')\n",
        "print_metrics(model_1, data_val, name='Val');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqfqmeoxY5ra",
        "outputId": "f4e38992-7749-45e7-c514-0538d74d6fb9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 14ms/step\n",
            "8/8 [==============================] - 1s 18ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 28ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 10ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 24ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 27ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 10ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 38ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 23ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 10ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 24ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 33ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 26ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 26ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 24ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 28ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 10ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 29ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 10ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 10ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 10ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 23ms/step\n",
            "8/8 [==============================] - 0s 33ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 10ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 23ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 23ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 28ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 29ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 25ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 23ms/step\n",
            "8/8 [==============================] - 0s 24ms/step\n",
            "8/8 [==============================] - 0s 25ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 24ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 23ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 1s 15ms/step\n",
            "Train results:\n",
            "Mean square error: 0.13764\n",
            "Mean absolute error: 0.28762\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 25ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 25ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 22ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 27ms/step\n",
            "8/8 [==============================] - 0s 23ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 24ms/step\n",
            "8/8 [==============================] - 0s 29ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 27ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 23ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 11ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 23ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 20ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 19ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "8/8 [==============================] - 0s 21ms/step\n",
            "8/8 [==============================] - 0s 18ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 12ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 27ms/step\n",
            "8/8 [==============================] - 0s 24ms/step\n",
            "8/8 [==============================] - 0s 15ms/step\n",
            "8/8 [==============================] - 0s 13ms/step\n",
            "8/8 [==============================] - 0s 16ms/step\n",
            "8/8 [==============================] - 0s 14ms/step\n",
            "8/8 [==============================] - 0s 17ms/step\n",
            "2/2 [==============================] - 0s 21ms/step\n",
            "Val results:\n",
            "Mean square error: 0.14098\n",
            "Mean absolute error: 0.29142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.save('model_1.keras')"
      ],
      "metadata": {
        "id": "fc4iolLubAdF"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5Gu07De2taG"
      },
      "source": [
        "### Bonus part: explaining model predictions\n",
        "\n",
        "It's usually a good idea to understand how your model works before you let it make actual decisions. It's simple for linear models: just see which words learned positive or negative weights. However, its much harder for neural networks that learn complex nonlinear dependencies.\n",
        "\n",
        "There are, however, some ways to look inside the black box:\n",
        "* Seeing how model responds to input perturbations\n",
        "* Finding inputs that maximize/minimize activation of some chosen neurons (_read more [on distill.pub](https://distill.pub/2018/building-blocks/)_)\n",
        "* Building local linear approximations to your neural network: [article](https://arxiv.org/abs/1602.04938), [eli5 library](https://github.com/TeamHG-Memex/eli5/tree/master/eli5/formatters)\n",
        "\n",
        "Today we gonna try the first method just because it's the simplest one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "q4EmiR4s2taG"
      },
      "outputs": [],
      "source": [
        "def explain(model, sample, col_name='Title'):\n",
        "    \"\"\" Computes the effect each word had on model predictions \"\"\"\n",
        "    sample = dict(sample)\n",
        "    sample_col_tokens = [tokens[token_to_id.get(tok, 0)] for tok in sample[col_name].split()]\n",
        "    data_drop_one_token = pd.DataFrame([sample] * (len(sample_col_tokens) + 1))\n",
        "\n",
        "    for drop_i in range(len(sample_col_tokens)):\n",
        "        data_drop_one_token.loc[drop_i, col_name] = ' '.join(UNK if i == drop_i else tok\n",
        "                                                   for i, tok in enumerate(sample_col_tokens))\n",
        "\n",
        "    *predictions_drop_one_token, baseline_pred = model.predict(make_batch(data_drop_one_token))[:, 0]\n",
        "    diffs = baseline_pred - predictions_drop_one_token\n",
        "    return list(zip(sample_col_tokens, diffs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "7DVhOoZq2taH"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display_html\n",
        "\n",
        "def draw_html(tokens_and_weights, cmap=plt.get_cmap(\"bwr\"), display=True,\n",
        "              token_template=\"\"\"<span style=\"background-color: {color_hex}\">{token}</span>\"\"\",\n",
        "              font_style=\"font-size:14px;\"\n",
        "             ):\n",
        "\n",
        "    def get_color_hex(weight):\n",
        "        rgba = cmap(1. / (1 + np.exp(weight)), bytes=True)\n",
        "        return '#%02X%02X%02X' % rgba[:3]\n",
        "\n",
        "    tokens_html = [\n",
        "        token_template.format(token=token, color_hex=get_color_hex(weight))\n",
        "        for token, weight in tokens_and_weights\n",
        "    ]\n",
        "\n",
        "\n",
        "    raw_html = \"\"\"<p style=\"{}\">{}</p>\"\"\".format(font_style, ' '.join(tokens_html))\n",
        "    if display:\n",
        "        display_html(HTML(raw_html))\n",
        "\n",
        "    return raw_html\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "ll905iKF2taI",
        "outputId": "ad716b78-3564-4bdd-825e-8e5deee9f85c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py:639: UserWarning: Input dict contained keys ['Log1pSalary'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 779ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"font-size:20px;\"><span style=\"background-color: #FEFEFF\">sales</span> <span style=\"background-color: #F6F6FF\">specialist</span> <span style=\"background-color: #F8F8FF\">iv</span> <span style=\"background-color: #F8F8FF\">access</span> <span style=\"background-color: #F8F8FF\">and</span> <span style=\"background-color: #ECECFF\">infusion</span></p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 0s 10ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"font-size:14px;\"><span style=\"background-color: #FFFAFA\">sales</span> <span style=\"background-color: #FF3636\">representative</span> <span style=\"background-color: #FF2C2C\">medical</span> <span style=\"background-color: #FF2C2C\">sales</span> <span style=\"background-color: #FF2929\">iv</span> <span style=\"background-color: #FF2929\">access</span> <span style=\"background-color: #FF2929\">and</span> <span style=\"background-color: #FF2929\">infusion</span> <span style=\"background-color: #FF2929\">an</span> <span style=\"background-color: #FF2929\">opportunity</span> <span style=\"background-color: #FF2929\">to</span> <span style=\"background-color: #FF2929\">work</span> <span style=\"background-color: #FF2929\">for</span> <span style=\"background-color: #FF2929\">the</span> <span style=\"background-color: #FF2929\">industry</span> <span style=\"background-color: #FF2929\">leading</span> <span style=\"background-color: #FF2929\">manufacturer</span> <span style=\"background-color: #FF2929\">of</span> <span style=\"background-color: #FF2929\">iv</span> <span style=\"background-color: #FF2929\">access</span> <span style=\"background-color: #FF2929\">and</span> <span style=\"background-color: #FF2929\">infusion</span> <span style=\"background-color: #FF2C2C\">solutions</span> <span style=\"background-color: #FF2828\">.</span> <span style=\"background-color: #FF2929\">formally</span> <span style=\"background-color: #FF2929\">recognised</span> <span style=\"background-color: #FF2929\">as</span> <span style=\"background-color: #FF2929\">the</span> <span style=\"background-color: #FF3434\">number</span> <span style=\"background-color: #FF2828\">****</span> <span style=\"background-color: #FF2C2C\">company</span> <span style=\"background-color: #FF2929\">in</span> <span style=\"background-color: #FF2929\">this</span> <span style=\"background-color: #FF2929\">market</span> <span style=\"background-color: #FF2C2C\">space</span> <span style=\"background-color: #FF2626\">,</span> <span style=\"background-color: #FF2929\">our</span> <span style=\"background-color: #FF2929\">client</span> <span style=\"background-color: #FF2929\">are</span> <span style=\"background-color: #FF2929\">an</span> <span style=\"background-color: #FF2929\">ethical</span> <span style=\"background-color: #FF2929\">and</span> <span style=\"background-color: #FF2929\">dynamic</span> <span style=\"background-color: #FF2929\">organisation</span> <span style=\"background-color: #FF2929\">absolutely</span> <span style=\"background-color: #FF2929\">committed</span> <span style=\"background-color: #FF2929\">to</span> <span style=\"background-color: #FF2929\">the</span> <span style=\"background-color: #FF2929\">advancement</span> <span style=\"background-color: #FF2929\">of</span> <span style=\"background-color: #FF2929\">innovative</span> <span style=\"background-color: #FF2929\">technologies</span> <span style=\"background-color: #FF2626\">.</span> <span style=\"background-color: #FF2929\">job</span> <span style=\"background-color: #FF2828\">title</span> <span style=\"background-color: #FF2828\">:</span> <span style=\"background-color: #FF2828\">sales</span> <span style=\"background-color: #FF2828\">specialist</span> <span style=\"background-color: #FF2828\">iv</span> <span style=\"background-color: #FF2828\">access</span> <span style=\"background-color: #FF2828\">and</span> <span style=\"background-color: #FF2828\">infusion</span> <span style=\"background-color: #FF2828\">selling</span> <span style=\"background-color: #FF2828\">:</span> <span style=\"background-color: #FF2828\">medication</span> <span style=\"background-color: #FF2828\">delivery</span> <span style=\"background-color: #FF2828\">solutions</span> <span style=\"background-color: #FF2828\">selling</span> <span style=\"background-color: #FF2828\">to</span> <span style=\"background-color: #FF2828\">:</span> <span style=\"background-color: #FF2828\">iv</span> <span style=\"background-color: #FF2929\">teams</span> <span style=\"background-color: #FF2424\">,</span> <span style=\"background-color: #FF2828\">infection</span> <span style=\"background-color: #FF2828\">control</span> <span style=\"background-color: #FF2424\">,</span> <span style=\"background-color: #FF2828\">lead</span> <span style=\"background-color: #FF2828\">intensive</span> <span style=\"background-color: #FF2828\">care</span> <span style=\"background-color: #FF2828\">nurse</span> <span style=\"background-color: #FF2828\">specialists</span> <span style=\"background-color: #FF2424\">,</span> <span style=\"background-color: #FF2626\">ward</span> <span style=\"background-color: #FF2626\">managers</span> <span style=\"background-color: #FF2626\">territory</span> <span style=\"background-color: #FF2626\">:</span> <span style=\"background-color: #FF2626\">east</span> <span style=\"background-color: #FF2626\">midlands</span> <span style=\"background-color: #FF2626\">location</span> <span style=\"background-color: #FF2626\">:</span> <span style=\"background-color: #FF2626\">east</span> <span style=\"background-color: #FF2626\">midlands</span> <span style=\"background-color: #FF2626\">package</span> <span style=\"background-color: #FF2626\">:</span> <span style=\"background-color: #FF2626\">basic</span> <span style=\"background-color: #FF3030\">:</span> <span style=\"background-color: #FF2424\">****</span> <span style=\"background-color: #FF3131\">k</span> <span style=\"background-color: #FF2626\">****</span> <span style=\"background-color: #FF2929\">k</span> <span style=\"background-color: #FF2424\">,</span> <span style=\"background-color: #FF2828\">uncapped</span> <span style=\"background-color: #FF2828\">bonus</span> <span style=\"background-color: #FF2828\">in</span> <span style=\"background-color: #FF2828\">addition</span> <span style=\"background-color: #FF2424\">,</span> <span style=\"background-color: #FF2626\">full</span> <span style=\"background-color: #FF2626\">corporate</span> <span style=\"background-color: #FF2626\">benefits</span> <span style=\"background-color: #FF2626\">company</span> <span style=\"background-color: #FF2626\">information</span> <span style=\"background-color: #FF2626\">hugely</span> <span style=\"background-color: #FF2626\">ethical</span> <span style=\"background-color: #FF2626\">and</span> <span style=\"background-color: #FF2626\">professional</span> <span style=\"background-color: #FF2626\">global</span> <span style=\"background-color: #FF2626\">organisation</span> <span style=\"background-color: #FF2626\">extremely</span> <span style=\"background-color: #FF2626\">well</span> <span style=\"background-color: #FF2626\">established</span> <span style=\"background-color: #FF2626\">in</span> <span style=\"background-color: #FF2626\">the</span> <span style=\"background-color: #FF2626\">uk</span> <span style=\"background-color: #FF2626\">the</span> <span style=\"background-color: #FF2626\">market</span> <span style=\"background-color: #FF2626\">leader</span> <span style=\"background-color: #FF2626\">across</span> <span style=\"background-color: #FF2626\">all</span> <span style=\"background-color: #FF2626\">of</span> <span style=\"background-color: #FF2626\">their</span> <span style=\"background-color: #FF2626\">core</span> <span style=\"background-color: #FF2626\">business</span> <span style=\"background-color: #FF2626\">areas</span> <span style=\"background-color: #FF2626\">focus</span> <span style=\"background-color: #FF2626\">on</span> <span style=\"background-color: #FF2626\">providing</span> <span style=\"background-color: #FF2626\">cutting</span> <span style=\"background-color: #FF2626\">edge</span> <span style=\"background-color: #FF2626\">solutions</span> <span style=\"background-color: #FF2626\">along</span> <span style=\"background-color: #FF2626\">with</span> <span style=\"background-color: #FF2626\">outstanding</span> <span style=\"background-color: #FF2626\">service</span> <span style=\"background-color: #FF2626\">and</span> <span style=\"background-color: #FF2626\">support</span> <span style=\"background-color: #FF2626\">a</span> <span style=\"background-color: #FF2626\">business</span> <span style=\"background-color: #FF2626\">that</span> <span style=\"background-color: #FF2626\">retain</span> <span style=\"background-color: #FF2626\">talented</span> <span style=\"background-color: #FF2626\">personnel</span> <span style=\"background-color: #FF2626\">by</span> <span style=\"background-color: #FF2626\">offering</span> <span style=\"background-color: #FF2626\">a</span> <span style=\"background-color: #FF2626\">strong</span> <span style=\"background-color: #FF2626\">platform</span> <span style=\"background-color: #FF2626\">for</span> <span style=\"background-color: #FF2626\">career</span> <span style=\"background-color: #FF2626\">development</span> <span style=\"background-color: #FF2626\">sales</span> <span style=\"background-color: #FF2626\">specialist</span> <span style=\"background-color: #FF2626\">iv</span> <span style=\"background-color: #FF2626\">access</span> <span style=\"background-color: #FF2626\">and</span> <span style=\"background-color: #FF2626\">infusion</span> <span style=\"background-color: #FF2626\">you</span> <span style=\"background-color: #FF2626\">must</span> <span style=\"background-color: #FF2626\">have</span> <span style=\"background-color: #FF2424\">/</span> <span style=\"background-color: #FF2626\">be</span> <span style=\"background-color: #FF2626\">the</span> <span style=\"background-color: #FF2626\">following</span> <span style=\"background-color: #FF2626\">at</span> <span style=\"background-color: #FF2626\">least</span> <span style=\"background-color: #FF2626\">2</span> <span style=\"background-color: #FF2626\">years</span> <span style=\"background-color: #FF2626\">medical</span> <span style=\"background-color: #FF2626\">device</span> <span style=\"background-color: #FF2626\">sales</span> <span style=\"background-color: #FF2626\">experience</span> <span style=\"background-color: #FF2424\">.</span> <span style=\"background-color: #FF2626\">candidates</span> <span style=\"background-color: #FF2626\">who</span> <span style=\"background-color: #FF2626\">have</span> <span style=\"background-color: #FF2626\">sold</span> <span style=\"background-color: #FF2626\">disposables</span> <span style=\"background-color: #FF2424\">/</span> <span style=\"background-color: #FF2626\">consumables</span> <span style=\"background-color: #FF2626\">or</span> <span style=\"background-color: #FF2626\">similar</span> <span style=\"background-color: #FF2626\">into</span> <span style=\"background-color: #FF2626\">hospitals</span> <span style=\"background-color: #FF2626\">would</span> <span style=\"background-color: #FF2626\">be</span> <span style=\"background-color: #FF2626\">of</span> <span style=\"background-color: #FF2626\">particular</span> <span style=\"background-color: #FF2626\">interest</span> <span style=\"background-color: #FF2121\">.</span> <span style=\"background-color: #FF2424\">candidates</span> <span style=\"background-color: #FF2424\">must</span> <span style=\"background-color: #FF2424\">have</span> <span style=\"background-color: #FF2424\">sold</span> <span style=\"background-color: #FF2424\">into</span> <span style=\"background-color: #FF2424\">hospitals</span> <span style=\"background-color: #FF2424\">demonstrable</span> <span style=\"background-color: #FF2424\">performance</span> <span style=\"background-color: #FF2424\">and</span> <span style=\"background-color: #FF2424\">achievements</span> <span style=\"background-color: #FF2424\">so</span> <span style=\"background-color: #FF2424\">far</span> <span style=\"background-color: #FF2626\">personable</span> <span style=\"background-color: #FF2121\">,</span> <span style=\"background-color: #FF2424\">adaptable</span> <span style=\"background-color: #FF2424\">and</span> <span style=\"background-color: #FF2424\">willing</span> <span style=\"background-color: #FF2424\">to</span> <span style=\"background-color: #FF2424\">learn</span> <span style=\"background-color: #FF2424\">keen</span> <span style=\"background-color: #FF2424\">and</span> <span style=\"background-color: #FF2424\">eager</span> <span style=\"background-color: #FF2424\">to</span> <span style=\"background-color: #FF2424\">be</span> <span style=\"background-color: #FF2424\">a</span> <span style=\"background-color: #FF2424\">success</span> <span style=\"background-color: #FF2424\">candidates</span> <span style=\"background-color: #FF2424\">must</span> <span style=\"background-color: #FF2424\">have</span> <span style=\"background-color: #FF2424\">a</span> <span style=\"background-color: #FF2424\">degree</span> <span style=\"background-color: #FF2424\">or</span> <span style=\"background-color: #FF2424\">at</span> <span style=\"background-color: #FF2424\">least</span> <span style=\"background-color: #FF2424\">be</span> <span style=\"background-color: #FF2424\">able</span> <span style=\"background-color: #FF2424\">to</span> <span style=\"background-color: #FF2424\">show</span> <span style=\"background-color: #FF2424\">a</span> <span style=\"background-color: #FF2424\">strong</span> <span style=\"background-color: #FF2424\">ability</span> <span style=\"background-color: #FF2424\">to</span> <span style=\"background-color: #FF2424\">learn</span> <span style=\"background-color: #FF2424\">role</span> <span style=\"background-color: #FF2424\">information</span> <span style=\"background-color: #FF2424\">managing</span> <span style=\"background-color: #FF2424\">the</span> <span style=\"background-color: #FF2424\">east</span> <span style=\"background-color: #FF2424\">midlands</span> <span style=\"background-color: #FF2424\">region</span> <span style=\"background-color: #FF2424\">selling</span> <span style=\"background-color: #FF2424\">across</span> <span style=\"background-color: #FF2424\">the</span> <span style=\"background-color: #FF3030\">company</span> <span style=\"background-color: #FF8E8E\">'</span> <span style=\"background-color: #FF2E2E\">s</span> <span style=\"background-color: #FF2626\">range</span> <span style=\"background-color: #FF2626\">of</span> <span style=\"background-color: #FF2626\">iv</span> <span style=\"background-color: #FF2626\">and</span> <span style=\"background-color: #FF2626\">infusion</span> <span style=\"background-color: #FF2626\">solutions</span> <span style=\"background-color: #FF2626\">portfolio</span> <span style=\"background-color: #FF2626\">selling</span> <span style=\"background-color: #FF2626\">into</span> <span style=\"background-color: #FF2626\">lead</span> <span style=\"background-color: #FF2626\">intensive</span> <span style=\"background-color: #FF2626\">care</span> <span style=\"background-color: #FF2626\">nurse</span> <span style=\"background-color: #FF2828\">specialists</span> <span style=\"background-color: #FF2121\">,</span> <span style=\"background-color: #FF2626\">ward</span> <span style=\"background-color: #FF2626\">managers</span> <span style=\"background-color: #FF2121\">,</span> <span style=\"background-color: #FF2626\">iv</span> <span style=\"background-color: #FF2626\">teams</span> <span style=\"background-color: #FF2121\">,</span> <span style=\"background-color: #FF2626\">infection</span> <span style=\"background-color: #FF2626\">control</span> <span style=\"background-color: #FF2626\">teams</span> <span style=\"background-color: #FF2121\">,</span> <span style=\"background-color: #FF2424\">procurement</span> <span style=\"background-color: #FF2424\">sales</span> <span style=\"background-color: #FF2424\">specialist</span> <span style=\"background-color: #FF2424\">iv</span> <span style=\"background-color: #FF2424\">access</span> <span style=\"background-color: #FF2424\">and</span> <span style=\"background-color: #FF2424\">infusion</span> <span style=\"background-color: #FF2424\">candidates</span> <span style=\"background-color: #FF2424\">must</span> <span style=\"background-color: #FF2424\">be</span> <span style=\"background-color: #FF2424\">eligible</span> <span style=\"background-color: #FF2424\">to</span> <span style=\"background-color: #FF2424\">work</span> <span style=\"background-color: #FF2424\">and</span> <span style=\"background-color: #FF2424\">live</span> <span style=\"background-color: #FF2424\">in</span> <span style=\"background-color: #FF2424\">the</span> <span style=\"background-color: #FF2424\">uk</span> <span style=\"background-color: #FF2121\">.</span> <span style=\"background-color: #FF2424\">please</span> <span style=\"background-color: #FF2424\">contact</span> <span style=\"background-color: #FF2424\">allan</span> <span style=\"background-color: #FF2424\">waller</span> <span style=\"background-color: #FF2C2C\">on</span> <span style=\"background-color: #FF2929\">****</span> <span style=\"background-color: #FF2C2C\">****</span> <span style=\"background-color: #FF2424\">****</span> <span style=\"background-color: #FF2626\">or</span> <span style=\"background-color: #FF2626\">please</span> <span style=\"background-color: #FF2626\">hit</span> <span style=\"background-color: #FF2626\">the</span> <span style=\"background-color: #FF2626\">apply</span> <span style=\"background-color: #FF2626\">button</span> <span style=\"background-color: #FF2121\">.</span> <span style=\"background-color: #FF2626\">this</span> <span style=\"background-color: #FF2424\">job</span> <span style=\"background-color: #FF2424\">was</span> <span style=\"background-color: #FF2424\">originally</span> <span style=\"background-color: #FF2424\">posted</span> <span style=\"background-color: #FF2424\">as</span> <span style=\"background-color: #FF2626\">www</span> <span style=\"background-color: #FF2121\">.</span> <span style=\"background-color: #FF2626\">salestarget</span> <span style=\"background-color: #FF2121\">.</span> <span style=\"background-color: #FF2424\">co</span> <span style=\"background-color: #FF2020\">.</span> <span style=\"background-color: #FF2424\">uk</span> <span style=\"background-color: #FF2121\">/</span> <span style=\"background-color: #FF2121\">jobseeking</span> <span style=\"background-color: #FF2424\">/</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #7474FF\">****</span></p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "i = 36605\n",
        "tokens_and_weights = explain(model_1, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model_1, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "r9cSpotA2taI",
        "outputId": "2682c2dc-455b-4b02-b216-538c1f80fc16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py:639: UserWarning: Input dict contained keys ['Log1pSalary'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 746ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"font-size:20px;\"><span style=\"background-color: #F3F3FF\">cleaning</span> <span style=\"background-color: #D6D6FF\">operative</span></p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"font-size:14px;\"><span style=\"background-color: #FFFEFE\">12</span> <span style=\"background-color: #FFB6B6\">.</span> <span style=\"background-color: #FFB0B0\">5</span> <span style=\"background-color: #FFAEAE\">hours</span> <span style=\"background-color: #FFAEAE\">per</span> <span style=\"background-color: #FFAEAE\">week</span> <span style=\"background-color: #FFAEAE\">monday</span> <span style=\"background-color: #FFAEAE\">friday</span> <span style=\"background-color: #FFAEAE\">9am</span> <span style=\"background-color: #FFAEAE\">11</span> <span style=\"background-color: #FFAEAE\">.</span> <span style=\"background-color: #FFAEAE\">30am</span> <span style=\"background-color: #FFAEAE\">duties</span> <span style=\"background-color: #FFAEAE\">to</span> <span style=\"background-color: #FFAEAE\">include</span> <span style=\"background-color: #FFAEAE\">sweeping</span> <span style=\"background-color: #FFAEAE\">,</span> <span style=\"background-color: #FFAEAE\">mopping</span> <span style=\"background-color: #FFAEAE\">,</span> <span style=\"background-color: #FFAEAE\">vacuuming</span> <span style=\"background-color: #FFAEAE\">,</span> <span style=\"background-color: #FFAEAE\">buffing</span> <span style=\"background-color: #FFAEAE\">,</span> <span style=\"background-color: #FFAEAE\">cleaning</span> <span style=\"background-color: #FFAEAE\">staff</span> <span style=\"background-color: #FFAEAE\">toilets</span> <span style=\"background-color: #FFAEAE\">and</span> <span style=\"background-color: #FFAEAE\">rest</span> <span style=\"background-color: #FFAEAE\">room</span> <span style=\"background-color: #FFAEAE\">.</span> <span style=\"background-color: #FFAEAE\">must</span> <span style=\"background-color: #FFAEAE\">be</span> <span style=\"background-color: #FFAEAE\">able</span> <span style=\"background-color: #FFAEAE\">to</span> <span style=\"background-color: #FFAEAE\">read</span> <span style=\"background-color: #FFAEAE\">as</span> <span style=\"background-color: #FFAEAE\">they</span> <span style=\"background-color: #FFAEAE\">will</span> <span style=\"background-color: #FFAEAE\">be</span> <span style=\"background-color: #FFC2C2\">using</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #FFC2C2\">which</span> <span style=\"background-color: #FFCCCC\">need</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #FFCCCC\">as</span> <span style=\"background-color: #FFAEAE\">per</span> <span style=\"background-color: #FFAEAE\">instructions</span> <span style=\"background-color: #FFAEAE\">on</span> <span style=\"background-color: #FFAEAE\">the</span> <span style=\"background-color: #FFAEAE\">containers</span> <span style=\"background-color: #FFAEAE\">.</span> <span style=\"background-color: #FFAEAE\">sucessfull</span> <span style=\"background-color: #FFAEAE\">applicants</span> <span style=\"background-color: #FFAEAE\">will</span> <span style=\"background-color: #FFAEAE\">be</span> <span style=\"background-color: #FFAEAE\">trained</span> <span style=\"background-color: #FFAEAE\">on</span> <span style=\"background-color: #FFAEAE\">all</span> <span style=\"background-color: #FFAEAE\">electrical</span> <span style=\"background-color: #FFAEAE\">appliances</span> <span style=\"background-color: #FFDADA\">and</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #FFDADA\">of</span> <span style=\"background-color: #FFAEAE\">cleaning</span> <span style=\"background-color: #FFA8A8\">materials</span> <span style=\"background-color: #FFEAEA\">.</span></p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "i = 12077\n",
        "tokens_and_weights = explain(model_1, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model_1, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "3Fw47j3o2taJ",
        "outputId": "3ff7cd25-6ea6-43e9-a234-99fd967b2356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 103928\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Salary (gbp): 16953.28\n",
            "1/1 [==============================] - 0s 50ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"font-size:20px;\"><span style=\"background-color: #FEFEFF\">social</span> <span style=\"background-color: #F6F6FF\">worker</span> <span style=\"background-color: #F8F8FF\">|</span> <span style=\"background-color: #F8F8FF\">looked</span> <span style=\"background-color: #F8F8FF\">after</span> <span style=\"background-color: #F8F8FF\">children</span> <span style=\"background-color: #F8F8FF\">|</span> <span style=\"background-color: #F8F8FF\">east</span> <span style=\"background-color: #ECECFF\">london</span></p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"font-size:14px;\"><span style=\"background-color: #FFF6F6\">social</span> <span style=\"background-color: #FF0C0C\">worker</span> <span style=\"background-color: #FF0808\">|</span> <span style=\"background-color: #FF0808\">looked</span> <span style=\"background-color: #FF0808\">after</span> <span style=\"background-color: #FF0808\">children</span> <span style=\"background-color: #FF0808\">|</span> <span style=\"background-color: #FF0808\">east</span> <span style=\"background-color: #FF0808\">london</span> <span style=\"background-color: #FF0808\">currently</span> <span style=\"background-color: #FF0808\">seeking</span> <span style=\"background-color: #FF0808\">a</span> <span style=\"background-color: #FF0808\">qualified</span> <span style=\"background-color: #FF0808\">social</span> <span style=\"background-color: #FF0808\">worker</span> <span style=\"background-color: #FF0808\">looked</span> <span style=\"background-color: #FF0808\">after</span> <span style=\"background-color: #FF0808\">children</span> <span style=\"background-color: #FF0808\">s</span> <span style=\"background-color: #FF0808\">services</span> <span style=\"background-color: #FF0808\">in</span> <span style=\"background-color: #FF0808\">east</span> <span style=\"background-color: #FF0808\">london</span> <span style=\"background-color: #FF0606\">.</span> <span style=\"background-color: #FF0808\">the</span> <span style=\"background-color: #FF0808\">required</span> <span style=\"background-color: #FF0808\">criteria</span> <span style=\"background-color: #FF0808\">is</span> <span style=\"background-color: #FF0808\">2</span> <span style=\"background-color: #FF0808\">years</span> <span style=\"background-color: #FF0808\">post</span> <span style=\"background-color: #FF0808\">qualifying</span> <span style=\"background-color: #FF0808\">experience</span> <span style=\"background-color: #FF0808\">for</span> <span style=\"background-color: #FF0808\">qualified</span> <span style=\"background-color: #FF0808\">social</span> <span style=\"background-color: #FF0808\">worker</span> <span style=\"background-color: #FF0808\">looked</span> <span style=\"background-color: #FF0808\">after</span> <span style=\"background-color: #FF0808\">children</span> <span style=\"background-color: #FF0808\">s</span> <span style=\"background-color: #FF0808\">services</span> <span style=\"background-color: #FF0808\">east</span> <span style=\"background-color: #FF0808\">london</span> <span style=\"background-color: #FF0606\">.</span> <span style=\"background-color: #FF0606\">you</span> <span style=\"background-color: #FF0606\">will</span> <span style=\"background-color: #FF0606\">have</span> <span style=\"background-color: #FF0606\">experience</span> <span style=\"background-color: #FF0606\">of</span> <span style=\"background-color: #FF0606\">:</span> <span style=\"background-color: #FF0606\">care</span> <span style=\"background-color: #FF0606\">proceedings</span> <span style=\"background-color: #FF0606\">working</span> <span style=\"background-color: #FF0606\">with</span> <span style=\"background-color: #FF0606\">children</span> <span style=\"background-color: #FF0606\">in</span> <span style=\"background-color: #FF0606\">care</span> <span style=\"background-color: #FF0606\">court</span> <span style=\"background-color: #FF0606\">work</span> <span style=\"background-color: #FF0606\">and</span> <span style=\"background-color: #FF0606\">final</span> <span style=\"background-color: #FF0606\">evidence</span> <span style=\"background-color: #FF0606\">children</span> <span style=\"background-color: #FF0606\">to</span> <span style=\"background-color: #FF0606\">adoption</span> <span style=\"background-color: #FF0606\">advocate</span> <span style=\"background-color: #FF0606\">meetings</span> <span style=\"background-color: #FF0606\">looked</span> <span style=\"background-color: #FF0606\">after</span> <span style=\"background-color: #FF0606\">children</span> <span style=\"background-color: #FF0606\">reviews</span> <span style=\"background-color: #FF0606\">you</span> <span style=\"background-color: #FF0606\">must</span> <span style=\"background-color: #FF0606\">be</span> <span style=\"background-color: #FF0606\">hcpc</span> <span style=\"background-color: #FF0606\">registered</span> <span style=\"background-color: #FF0606\">eligible</span> <span style=\"background-color: #FF0606\">to</span> <span style=\"background-color: #FF0606\">work</span> <span style=\"background-color: #FF0606\">in</span> <span style=\"background-color: #FF0606\">the</span> <span style=\"background-color: #FF0606\">uk</span> <span style=\"background-color: #FF0606\">car</span> <span style=\"background-color: #FF0606\">driver</span> <span style=\"background-color: #FF0606\">salary</span> <span style=\"background-color: #FF0606\">range</span> <span style=\"background-color: #FF0909\">is</span> <span style=\"background-color: #FF0808\">****</span> <span style=\"background-color: #FF0909\">ph</span> <span style=\"background-color: #FF0606\">****</span> <span style=\"background-color: #FF0808\">social</span> <span style=\"background-color: #FF0606\">work</span> <span style=\"background-color: #FF0606\">is</span> <span style=\"background-color: #FF0606\">a</span> <span style=\"background-color: #FF0606\">specialist</span> <span style=\"background-color: #FF0606\">recruitment</span> <span style=\"background-color: #FF0606\">agency</span> <span style=\"background-color: #FF0606\">for</span> <span style=\"background-color: #FF0606\">qualified</span> <span style=\"background-color: #FF0606\">social</span> <span style=\"background-color: #FF0606\">workers</span> <span style=\"background-color: #FF0606\">and</span> <span style=\"background-color: #FF0606\">care</span> <span style=\"background-color: #FF0606\">professionals</span> <span style=\"background-color: #FF0606\">.</span> <span style=\"background-color: #FF0606\">we</span> <span style=\"background-color: #FF0606\">offer</span> <span style=\"background-color: #FF0606\">.</span> <span style=\"background-color: #FF0606\">bonuses</span> <span style=\"background-color: #FF0606\">for</span> <span style=\"background-color: #FF0606\">your</span> <span style=\"background-color: #FF0606\">loyalty</span> <span style=\"background-color: #FF0606\">and</span> <span style=\"background-color: #FF0606\">referrals</span> <span style=\"background-color: #FF0606\">training</span> <span style=\"background-color: #FF0606\">opportunities</span> <span style=\"background-color: #FF0606\">and</span> <span style=\"background-color: #FF0606\">professional</span> <span style=\"background-color: #FF0606\">development</span> <span style=\"background-color: #FF0606\">full</span> <span style=\"background-color: #FF0606\">support</span> <span style=\"background-color: #FF0606\">by</span> <span style=\"background-color: #FF0606\">an</span> <span style=\"background-color: #FF0606\">expert</span> <span style=\"background-color: #FF0606\">social</span> <span style=\"background-color: #FF0606\">work</span> <span style=\"background-color: #FF0606\">consultant</span> <span style=\"background-color: #FF0808\">team</span> <span style=\"background-color: #FF0606\">****</span> <span style=\"background-color: #FF0606\">social</span> <span style=\"background-color: #FF0606\">work</span> <span style=\"background-color: #FF0606\">employee</span> <span style=\"background-color: #FF0606\">benefits</span> <span style=\"background-color: #FF0606\">programme</span> <span style=\"background-color: #FF0606\">for</span> <span style=\"background-color: #FF0606\">more</span> <span style=\"background-color: #FF0606\">information</span> <span style=\"background-color: #FF0606\">and</span> <span style=\"background-color: #FF0606\">to</span> <span style=\"background-color: #FF0606\">find</span> <span style=\"background-color: #FF0606\">other</span> <span style=\"background-color: #FF0606\">vacancies</span> <span style=\"background-color: #FF0606\">in</span> <span style=\"background-color: #FF0606\">your</span> <span style=\"background-color: #FF0606\">area</span> <span style=\"background-color: #FF0606\">contact</span> <span style=\"background-color: #FF0606\">simba</span> <span style=\"background-color: #FF0606\">garande</span> <span style=\"background-color: #FF0808\">on</span> <span style=\"background-color: #FF0808\">****</span> <span style=\"background-color: #FF0909\">****</span> <span style=\"background-color: #FF0808\">****</span> <span style=\"background-color: #FF0808\">who</span> <span style=\"background-color: #FF0606\">cares</span> <span style=\"background-color: #FF0606\">?</span> <span style=\"background-color: #FF0606\">we</span> <span style=\"background-color: #FF0606\">do</span> <span style=\"background-color: #FFF6F6\">.</span></p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "i = np.random.randint(len(data))\n",
        "print(\"Index:\", i)\n",
        "print(\"Salary (gbp):\", np.expm1(model_1.predict(make_batch(data.iloc[i: i+1]))[0, 0]))\n",
        "\n",
        "tokens_and_weights = explain(model_1, data.loc[i], \"Title\")\n",
        "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
        "\n",
        "tokens_and_weights = explain(model_1, data.loc[i], \"FullDescription\")\n",
        "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5dZeqyp2taK"
      },
      "source": [
        "__Terrible start-up idea #1962:__ make a tool that automaticaly rephrases your job description (or CV) to meet salary expectations :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqS4jKVi2taK"
      },
      "source": [
        "## Final task: improve over it\n",
        "\n",
        "Your main task is to use some of the tricks you've learned on the network and analyze if you can improve __validation MAE__. Try __at least 3 options__ from the list below for a full grade. Write a short report about what you have tried. More ideas = more bonus points.\n",
        "\n",
        "__Please be serious:__ \" plot learning curves in MAE/epoch, compare models based on optimal performance, test one change at a time. You know this stuff.\n",
        "\n",
        "#### A) CNN architecture\n",
        "\n",
        "All the tricks you know about dense and convolutional neural networks apply here as well.\n",
        "* Dropout.\n",
        "* Batch Norm.\n",
        "* Parallel convolution layers. The idea is that you apply several nn.Conv1d to the same embeddings and concatenate output channels.\n",
        "* More layers, more neurons\n",
        "\n",
        "\n",
        "#### B) Play with pooling\n",
        "\n",
        "There's more than one way to perform pooling:\n",
        "* Max over time - our `L.GlobalMaxPool1D`\n",
        "* Average over time (excluding PAD)\n",
        "* Softmax-pooling:\n",
        "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot {{e ^ {h_{i, t}}} \\over \\sum_\\tau e ^ {h_{j, \\tau}} } }$$\n",
        "\n",
        "* Attentive pooling\n",
        "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot Attn(h_t)}$$\n",
        "\n",
        ", where $$ Attn(h_t) = {{e ^ {NN_{attn}(h_t)}} \\over \\sum_\\tau e ^ {NN_{attn}(h_\\tau)}}  $$\n",
        "and $NN_{attn}$ is a dense layer.\n",
        "\n",
        "The optimal score is usually achieved by concatenating several different poolings, including several attentive pooling with different $NN_{attn}$ (aka multi-headed attention).\n",
        "\n",
        "The catch is that keras layers do not inlude those toys. You will have to [write your own keras layer](https://keras.io/layers/writing-your-own-keras-layers/).\n",
        "\n",
        "#### C) Fun with words\n",
        "\n",
        "It's not always a good idea to train embeddings from scratch. Here's a few tricks:\n",
        "\n",
        "* Use a pre-trained embeddings from `gensim.downloader.load`. See last lecture.\n",
        "* Start with pre-trained embeddings, then fine-tune them with gradient descent. You may or may not want to use __`.get_keras_embedding()`__ method for word2vec\n",
        "* Use the same embedding matrix in title and desc vectorizer\n",
        "\n",
        "\n",
        "#### D) Going recurrent\n",
        "\n",
        "We've already learned that recurrent networks can do cool stuff in sequence modelling. Turns out, they're not useless for classification as well. With some tricks of course..\n",
        "\n",
        "* Like convolutional layers, LSTM should be pooled into a fixed-size vector with some of the poolings.\n",
        "* Since you know all the text in advance, use bidirectional RNN\n",
        "  * Run one LSTM from left to right\n",
        "  * Run another in parallel from right to left\n",
        "  * Concatenate their output sequences along unit axis (dim=-1)\n",
        "\n",
        "* It might be good idea to mix convolutions and recurrent layers differently for title and description\n",
        "\n",
        "\n",
        "#### E) Optimizing seriously\n",
        "\n",
        "* You don't necessarily need 100 epochs. Use early stopping. If you've never done this before, take a look at [early stopping callback](https://keras.io/api/callbacks/early_stopping/).\n",
        "  * In short, train until you notice that validation\n",
        "  * Maintain the best-on-validation snapshot via `model.save(file_name)`\n",
        "  * Plotting learning curves is usually a good idea\n",
        "  \n",
        "Good luck!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}